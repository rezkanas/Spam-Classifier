{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07abc1ef",
   "metadata": {},
   "source": [
    "# Selecting Naive Bayes's Hyperparameters:\n",
    " I have considered here multiple combinations of:\n",
    "  * **Alpha** is the constant used in laplace smoothing. \n",
    "  * **Number Fold** is the numbers of foldes that training data are split into. This is used in cross valdiation excercise. \n",
    "\n",
    "Plug a series of combination in `create_classifier` in order to measure the weighted overall accuracy on unseen data. I then select the hyperparameters that got the best accuracy to go into the final module that I used for prediction on test data.  \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1397c20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
      "Weighted accuracy is 0.8955000000000001 when alpha and k-folds are (0.1, 10) respectively.\n",
      "\n",
      "Accuracy on test data is: 0.896, averaged accuracy on train data is: 0.8930000000000003\n",
      "This took 1 seconds to solve.\n",
      "\n",
      "\n",
      "**The best overall accuracy on test data is so far standing at: 0.8955000000000001 when alpha and k-folds are (0.1, 10)\n",
      "Modules with similar accuracy (if any) have the following hyperparameters (hyperparameters:[weight accuracy, accuracy, max_accuracy_train, max_time]) : {}\n",
      "\n",
      "\n",
      "\n",
      "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
      "Weighted accuracy is 0.8956363636363637 when alpha and k-folds are (0.1, 20) respectively.\n",
      "\n",
      "Accuracy on test data is: 0.896, averaged accuracy on train data is: 0.8920000000000001\n",
      "This took 2 seconds to solve.\n",
      "\n",
      "\n",
      "**The best overall accuracy on test data is so far standing at: 0.8956363636363637 when alpha and k-folds are (0.1, 20)\n",
      "Modules with similar accuracy (if any) have the following hyperparameters (hyperparameters:[weight accuracy, accuracy, max_accuracy_train, max_time]) : {}\n",
      "\n",
      "\n",
      "\n",
      "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
      "Weighted accuracy is 0.8957037037037037 when alpha and k-folds are (0.1, 25) respectively.\n",
      "\n",
      "Accuracy on test data is: 0.896, averaged accuracy on train data is: 0.8920000000000003\n",
      "This took 2 seconds to solve.\n",
      "\n",
      "\n",
      "**The best overall accuracy on test data is so far standing at: 0.8957037037037037 when alpha and k-folds are (0.1, 25)\n",
      "Modules with similar accuracy (if any) have the following hyperparameters (hyperparameters:[weight accuracy, accuracy, max_accuracy_train, max_time]) : {}\n",
      "\n",
      "\n",
      "\n",
      "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
      "Weighted accuracy is 0.8958846153846154 when alpha and k-folds are (0.1, 50) respectively.\n",
      "\n",
      "Accuracy on test data is: 0.896, averaged accuracy on train data is: 0.893\n",
      "This took 3 seconds to solve.\n",
      "\n",
      "\n",
      "**The best overall accuracy on test data is so far standing at: 0.8958846153846154 when alpha and k-folds are (0.1, 50)\n",
      "Modules with similar accuracy (if any) have the following hyperparameters (hyperparameters:[weight accuracy, accuracy, max_accuracy_train, max_time]) : {}\n",
      "\n",
      "\n",
      "\n",
      "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
      "Weighted accuracy is 0.8978627450980392 when alpha and k-folds are (0.1, 100) respectively.\n",
      "\n",
      "Accuracy on test data is: 0.898, averaged accuracy on train data is: 0.8909999999999998\n",
      "This took 3 seconds to solve.\n",
      "\n",
      "\n",
      "**The best overall accuracy on test data is so far standing at: 0.8978627450980392 when alpha and k-folds are (0.1, 100)\n",
      "Modules with similar accuracy (if any) have the following hyperparameters (hyperparameters:[weight accuracy, accuracy, max_accuracy_train, max_time]) : {}\n",
      "\n",
      "\n",
      "\n",
      "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
      "Weighted accuracy is 0.895950495049505 when alpha and k-folds are (0.1, 200) respectively.\n",
      "\n",
      "Accuracy on test data is: 0.896, averaged accuracy on train data is: 0.891\n",
      "This took 3 seconds to solve.\n",
      "\n",
      "\n",
      "**The best overall accuracy on test data is so far standing at: 0.8978627450980392 when alpha and k-folds are (0.1, 100)\n",
      "Modules with similar accuracy (if any) have the following hyperparameters (hyperparameters:[weight accuracy, accuracy, max_accuracy_train, max_time]) : {}\n",
      "\n",
      "\n",
      "\n",
      "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
      "Weighted accuracy is 0.9079402390438247 when alpha and k-folds are (0.1, 500) respectively.\n",
      "\n",
      "Accuracy on test data is: 0.908, averaged accuracy on train data is: 0.893\n",
      "This took 3 seconds to solve.\n",
      "\n",
      "\n",
      "**The best overall accuracy on test data is so far standing at: 0.9079402390438247 when alpha and k-folds are (0.1, 500)\n",
      "Modules with similar accuracy (if any) have the following hyperparameters (hyperparameters:[weight accuracy, accuracy, max_accuracy_train, max_time]) : {}\n",
      "\n",
      "\n",
      "\n",
      "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
      "Weighted accuracy is 0.8971666666666667 when alpha and k-folds are (1, 10) respectively.\n",
      "\n",
      "Accuracy on test data is: 0.898, averaged accuracy on train data is: 0.8930000000000003\n",
      "This took 5 seconds to solve.\n",
      "\n",
      "\n",
      "**The best overall accuracy on test data is so far standing at: 0.9079402390438247 when alpha and k-folds are (0.1, 500)\n",
      "Modules with similar accuracy (if any) have the following hyperparameters (hyperparameters:[weight accuracy, accuracy, max_accuracy_train, max_time]) : {}\n",
      "\n",
      "\n",
      "\n",
      "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
      "Weighted accuracy is 0.8975454545454546 when alpha and k-folds are (1, 20) respectively.\n",
      "\n",
      "Accuracy on test data is: 0.898, averaged accuracy on train data is: 0.8930000000000001\n",
      "This took 5 seconds to solve.\n",
      "\n",
      "\n",
      "**The best overall accuracy on test data is so far standing at: 0.9079402390438247 when alpha and k-folds are (0.1, 500)\n",
      "Modules with similar accuracy (if any) have the following hyperparameters (hyperparameters:[weight accuracy, accuracy, max_accuracy_train, max_time]) : {}\n",
      "\n",
      "\n",
      "\n",
      "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
      "Weighted accuracy is 0.8975555555555556 when alpha and k-folds are (1, 25) respectively.\n",
      "\n",
      "Accuracy on test data is: 0.898, averaged accuracy on train data is: 0.8920000000000003\n",
      "This took 6 seconds to solve.\n",
      "\n",
      "\n",
      "**The best overall accuracy on test data is so far standing at: 0.9079402390438247 when alpha and k-folds are (0.1, 500)\n",
      "Modules with similar accuracy (if any) have the following hyperparameters (hyperparameters:[weight accuracy, accuracy, max_accuracy_train, max_time]) : {}\n",
      "\n",
      "\n",
      "\n",
      "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
      "Weighted accuracy is 0.8977692307692308 when alpha and k-folds are (1, 50) respectively.\n",
      "\n",
      "Accuracy on test data is: 0.898, averaged accuracy on train data is: 0.892\n",
      "This took 6 seconds to solve.\n",
      "\n",
      "\n",
      "**The best overall accuracy on test data is so far standing at: 0.9079402390438247 when alpha and k-folds are (0.1, 500)\n",
      "Modules with similar accuracy (if any) have the following hyperparameters (hyperparameters:[weight accuracy, accuracy, max_accuracy_train, max_time]) : {}\n",
      "\n",
      "\n",
      "\n",
      "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
      "Weighted accuracy is 0.8998039215686274 when alpha and k-folds are (1, 100) respectively.\n",
      "\n",
      "Accuracy on test data is: 0.9, averaged accuracy on train data is: 0.8899999999999999\n",
      "This took 7 seconds to solve.\n",
      "\n",
      "\n",
      "**The best overall accuracy on test data is so far standing at: 0.9079402390438247 when alpha and k-folds are (0.1, 500)\n",
      "Modules with similar accuracy (if any) have the following hyperparameters (hyperparameters:[weight accuracy, accuracy, max_accuracy_train, max_time]) : {}\n",
      "\n",
      "\n",
      "\n",
      "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
      "Weighted accuracy is 0.897930693069307 when alpha and k-folds are (1, 200) respectively.\n",
      "\n",
      "Accuracy on test data is: 0.898, averaged accuracy on train data is: 0.891\n",
      "This took 7 seconds to solve.\n",
      "\n",
      "\n",
      "**The best overall accuracy on test data is so far standing at: 0.9079402390438247 when alpha and k-folds are (0.1, 500)\n",
      "Modules with similar accuracy (if any) have the following hyperparameters (hyperparameters:[weight accuracy, accuracy, max_accuracy_train, max_time]) : {}\n",
      "\n",
      "\n",
      "\n",
      "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
      "Weighted accuracy is 0.9039561752988048 when alpha and k-folds are (1, 500) respectively.\n",
      "\n",
      "Accuracy on test data is: 0.904, averaged accuracy on train data is: 0.893\n",
      "This took 7 seconds to solve.\n",
      "\n",
      "\n",
      "**The best overall accuracy on test data is so far standing at: 0.9079402390438247 when alpha and k-folds are (0.1, 500)\n",
      "Modules with similar accuracy (if any) have the following hyperparameters (hyperparameters:[weight accuracy, accuracy, max_accuracy_train, max_time]) : {}\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
      "Weighted accuracy is 0.9005000000000001 when alpha and k-folds are (1.5, 10) respectively.\n",
      "\n",
      "Accuracy on test data is: 0.902, averaged accuracy on train data is: 0.8930000000000003\n",
      "This took 8 seconds to solve.\n",
      "\n",
      "\n",
      "**The best overall accuracy on test data is so far standing at: 0.9079402390438247 when alpha and k-folds are (0.1, 500)\n",
      "Modules with similar accuracy (if any) have the following hyperparameters (hyperparameters:[weight accuracy, accuracy, max_accuracy_train, max_time]) : {}\n",
      "\n",
      "\n",
      "\n",
      "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
      "Weighted accuracy is 0.9011818181818181 when alpha and k-folds are (1.5, 20) respectively.\n",
      "\n",
      "Accuracy on test data is: 0.902, averaged accuracy on train data is: 0.8930000000000001\n",
      "This took 9 seconds to solve.\n",
      "\n",
      "\n",
      "**The best overall accuracy on test data is so far standing at: 0.9079402390438247 when alpha and k-folds are (0.1, 500)\n",
      "Modules with similar accuracy (if any) have the following hyperparameters (hyperparameters:[weight accuracy, accuracy, max_accuracy_train, max_time]) : {}\n",
      "\n",
      "\n",
      "\n",
      "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
      "Weighted accuracy is 0.8993333333333334 when alpha and k-folds are (1.5, 25) respectively.\n",
      "\n",
      "Accuracy on test data is: 0.9, averaged accuracy on train data is: 0.8910000000000003\n",
      "This took 9 seconds to solve.\n",
      "\n",
      "\n",
      "**The best overall accuracy on test data is so far standing at: 0.9079402390438247 when alpha and k-folds are (0.1, 500)\n",
      "Modules with similar accuracy (if any) have the following hyperparameters (hyperparameters:[weight accuracy, accuracy, max_accuracy_train, max_time]) : {}\n",
      "\n",
      "\n",
      "\n",
      "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
      "Weighted accuracy is 0.8997307692307692 when alpha and k-folds are (1.5, 50) respectively.\n",
      "\n",
      "Accuracy on test data is: 0.9, averaged accuracy on train data is: 0.893\n",
      "This took 10 seconds to solve.\n",
      "\n",
      "\n",
      "**The best overall accuracy on test data is so far standing at: 0.9079402390438247 when alpha and k-folds are (0.1, 500)\n",
      "Modules with similar accuracy (if any) have the following hyperparameters (hyperparameters:[weight accuracy, accuracy, max_accuracy_train, max_time]) : {}\n",
      "\n",
      "\n",
      "\n",
      "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
      "Weighted accuracy is 0.9017647058823529 when alpha and k-folds are (1.5, 100) respectively.\n",
      "\n",
      "Accuracy on test data is: 0.902, averaged accuracy on train data is: 0.8899999999999999\n",
      "This took 10 seconds to solve.\n",
      "\n",
      "\n",
      "**The best overall accuracy on test data is so far standing at: 0.9079402390438247 when alpha and k-folds are (0.1, 500)\n",
      "Modules with similar accuracy (if any) have the following hyperparameters (hyperparameters:[weight accuracy, accuracy, max_accuracy_train, max_time]) : {}\n",
      "\n",
      "\n",
      "\n",
      "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
      "Weighted accuracy is 0.9038613861386139 when alpha and k-folds are (1.5, 200) respectively.\n",
      "\n",
      "Accuracy on test data is: 0.904, averaged accuracy on train data is: 0.89\n",
      "This took 10 seconds to solve.\n",
      "\n",
      "\n",
      "**The best overall accuracy on test data is so far standing at: 0.9079402390438247 when alpha and k-folds are (0.1, 500)\n",
      "Modules with similar accuracy (if any) have the following hyperparameters (hyperparameters:[weight accuracy, accuracy, max_accuracy_train, max_time]) : {}\n",
      "\n",
      "\n",
      "\n",
      "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
      "Weighted accuracy is 0.9059482071713147 when alpha and k-folds are (1.5, 500) respectively.\n",
      "\n",
      "Accuracy on test data is: 0.906, averaged accuracy on train data is: 0.893\n",
      "This took 10 seconds to solve.\n",
      "\n",
      "\n",
      "**The best overall accuracy on test data is so far standing at: 0.9079402390438247 when alpha and k-folds are (0.1, 500)\n",
      "Modules with similar accuracy (if any) have the following hyperparameters (hyperparameters:[weight accuracy, accuracy, max_accuracy_train, max_time]) : {}\n",
      "\n",
      "\n",
      "\n",
      "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
      "Weighted accuracy is 0.9005000000000001 when alpha and k-folds are (2, 10) respectively.\n",
      "\n",
      "Accuracy on test data is: 0.902, averaged accuracy on train data is: 0.8930000000000003\n",
      "This took 11 seconds to solve.\n",
      "\n",
      "\n",
      "**The best overall accuracy on test data is so far standing at: 0.9079402390438247 when alpha and k-folds are (0.1, 500)\n",
      "Modules with similar accuracy (if any) have the following hyperparameters (hyperparameters:[weight accuracy, accuracy, max_accuracy_train, max_time]) : {}\n",
      "\n",
      "\n",
      "\n",
      "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
      "Weighted accuracy is 0.901090909090909 when alpha and k-folds are (2, 20) respectively.\n",
      "\n",
      "Accuracy on test data is: 0.902, averaged accuracy on train data is: 0.892\n",
      "This took 12 seconds to solve.\n",
      "\n",
      "\n",
      "**The best overall accuracy on test data is so far standing at: 0.9079402390438247 when alpha and k-folds are (0.1, 500)\n",
      "Modules with similar accuracy (if any) have the following hyperparameters (hyperparameters:[weight accuracy, accuracy, max_accuracy_train, max_time]) : {}\n",
      "\n",
      "\n",
      "\n",
      "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
      "Weighted accuracy is 0.9030370370370371 when alpha and k-folds are (2, 25) respectively.\n",
      "\n",
      "Accuracy on test data is: 0.904, averaged accuracy on train data is: 0.8910000000000003\n",
      "This took 13 seconds to solve.\n",
      "\n",
      "\n",
      "**The best overall accuracy on test data is so far standing at: 0.9079402390438247 when alpha and k-folds are (0.1, 500)\n",
      "Modules with similar accuracy (if any) have the following hyperparameters (hyperparameters:[weight accuracy, accuracy, max_accuracy_train, max_time]) : {}\n",
      "\n",
      "\n",
      "\n",
      "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
      "Weighted accuracy is 0.9016153846153846 when alpha and k-folds are (2, 50) respectively.\n",
      "\n",
      "Accuracy on test data is: 0.902, averaged accuracy on train data is: 0.892\n",
      "This took 13 seconds to solve.\n",
      "\n",
      "\n",
      "**The best overall accuracy on test data is so far standing at: 0.9079402390438247 when alpha and k-folds are (0.1, 500)\n",
      "Modules with similar accuracy (if any) have the following hyperparameters (hyperparameters:[weight accuracy, accuracy, max_accuracy_train, max_time]) : {}\n",
      "\n",
      "\n",
      "\n",
      "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
      "Weighted accuracy is 0.9056470588235294 when alpha and k-folds are (2, 100) respectively.\n",
      "\n",
      "Accuracy on test data is: 0.906, averaged accuracy on train data is: 0.8879999999999999\n",
      "This took 13 seconds to solve.\n",
      "\n",
      "\n",
      "**The best overall accuracy on test data is so far standing at: 0.9079402390438247 when alpha and k-folds are (0.1, 500)\n",
      "Modules with similar accuracy (if any) have the following hyperparameters (hyperparameters:[weight accuracy, accuracy, max_accuracy_train, max_time]) : {}\n",
      "\n",
      "\n",
      "\n",
      "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
      "Weighted accuracy is 0.9018811881188119 when alpha and k-folds are (2, 200) respectively.\n",
      "\n",
      "Accuracy on test data is: 0.902, averaged accuracy on train data is: 0.89\n",
      "This took 13 seconds to solve.\n",
      "\n",
      "\n",
      "**The best overall accuracy on test data is so far standing at: 0.9079402390438247 when alpha and k-folds are (0.1, 500)\n",
      "Modules with similar accuracy (if any) have the following hyperparameters (hyperparameters:[weight accuracy, accuracy, max_accuracy_train, max_time]) : {}\n",
      "\n",
      "\n",
      "\n",
      "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
      "Weighted accuracy is 0.9059442231075697 when alpha and k-folds are (2, 500) respectively.\n",
      "\n",
      "Accuracy on test data is: 0.906, averaged accuracy on train data is: 0.892\n",
      "This took 13 seconds to solve.\n",
      "\n",
      "\n",
      "**The best overall accuracy on test data is so far standing at: 0.9079402390438247 when alpha and k-folds are (0.1, 500)\n",
      "Modules with similar accuracy (if any) have the following hyperparameters (hyperparameters:[weight accuracy, accuracy, max_accuracy_train, max_time]) : {}\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
      "Weighted accuracy is 0.9005000000000001 when alpha and k-folds are (2.5, 10) respectively.\n",
      "\n",
      "Accuracy on test data is: 0.902, averaged accuracy on train data is: 0.8930000000000003\n",
      "This took 15 seconds to solve.\n",
      "\n",
      "\n",
      "**The best overall accuracy on test data is so far standing at: 0.9079402390438247 when alpha and k-folds are (0.1, 500)\n",
      "Modules with similar accuracy (if any) have the following hyperparameters (hyperparameters:[weight accuracy, accuracy, max_accuracy_train, max_time]) : {}\n",
      "\n",
      "\n",
      "\n",
      "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
      "Weighted accuracy is 0.901090909090909 when alpha and k-folds are (2.5, 20) respectively.\n",
      "\n",
      "Accuracy on test data is: 0.902, averaged accuracy on train data is: 0.892\n",
      "This took 15 seconds to solve.\n",
      "\n",
      "\n",
      "**The best overall accuracy on test data is so far standing at: 0.9079402390438247 when alpha and k-folds are (0.1, 500)\n",
      "Modules with similar accuracy (if any) have the following hyperparameters (hyperparameters:[weight accuracy, accuracy, max_accuracy_train, max_time]) : {}\n",
      "\n",
      "\n",
      "\n",
      "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
      "Weighted accuracy is 0.9011851851851852 when alpha and k-folds are (2.5, 25) respectively.\n",
      "\n",
      "Accuracy on test data is: 0.902, averaged accuracy on train data is: 0.8910000000000003\n",
      "This took 16 seconds to solve.\n",
      "\n",
      "\n",
      "**The best overall accuracy on test data is so far standing at: 0.9079402390438247 when alpha and k-folds are (0.1, 500)\n",
      "Modules with similar accuracy (if any) have the following hyperparameters (hyperparameters:[weight accuracy, accuracy, max_accuracy_train, max_time]) : {}\n",
      "\n",
      "\n",
      "\n",
      "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
      "Weighted accuracy is 0.8996923076923077 when alpha and k-folds are (2.5, 50) respectively.\n",
      "\n",
      "Accuracy on test data is: 0.9, averaged accuracy on train data is: 0.892\n",
      "This took 16 seconds to solve.\n",
      "\n",
      "\n",
      "**The best overall accuracy on test data is so far standing at: 0.9079402390438247 when alpha and k-folds are (0.1, 500)\n",
      "Modules with similar accuracy (if any) have the following hyperparameters (hyperparameters:[weight accuracy, accuracy, max_accuracy_train, max_time]) : {}\n",
      "\n",
      "\n",
      "\n",
      "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
      "Weighted accuracy is 0.9036666666666666 when alpha and k-folds are (2.5, 100) respectively.\n",
      "\n",
      "Accuracy on test data is: 0.904, averaged accuracy on train data is: 0.8869999999999999\n",
      "This took 16 seconds to solve.\n",
      "\n",
      "\n",
      "**The best overall accuracy on test data is so far standing at: 0.9079402390438247 when alpha and k-folds are (0.1, 500)\n",
      "Modules with similar accuracy (if any) have the following hyperparameters (hyperparameters:[weight accuracy, accuracy, max_accuracy_train, max_time]) : {}\n",
      "\n",
      "\n",
      "\n",
      "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
      "Weighted accuracy is 0.9018910891089109 when alpha and k-folds are (2.5, 200) respectively.\n",
      "\n",
      "Accuracy on test data is: 0.902, averaged accuracy on train data is: 0.891\n",
      "This took 16 seconds to solve.\n",
      "\n",
      "\n",
      "**The best overall accuracy on test data is so far standing at: 0.9079402390438247 when alpha and k-folds are (0.1, 500)\n",
      "Modules with similar accuracy (if any) have the following hyperparameters (hyperparameters:[weight accuracy, accuracy, max_accuracy_train, max_time]) : {}\n",
      "\n",
      "\n",
      "\n",
      "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
      "Weighted accuracy is 0.9059482071713147 when alpha and k-folds are (2.5, 500) respectively.\n",
      "\n",
      "Accuracy on test data is: 0.906, averaged accuracy on train data is: 0.893\n",
      "This took 16 seconds to solve.\n",
      "\n",
      "\n",
      "**The best overall accuracy on test data is so far standing at: 0.9079402390438247 when alpha and k-folds are (0.1, 500)\n",
      "Modules with similar accuracy (if any) have the following hyperparameters (hyperparameters:[weight accuracy, accuracy, max_accuracy_train, max_time]) : {}\n",
      "\n",
      "\n",
      "\n",
      "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
      "Weighted accuracy is 0.9003333333333334 when alpha and k-folds are (3, 10) respectively.\n",
      "\n",
      "Accuracy on test data is: 0.902, averaged accuracy on train data is: 0.8920000000000003\n",
      "This took 18 seconds to solve.\n",
      "\n",
      "\n",
      "**The best overall accuracy on test data is so far standing at: 0.9079402390438247 when alpha and k-folds are (0.1, 500)\n",
      "Modules with similar accuracy (if any) have the following hyperparameters (hyperparameters:[weight accuracy, accuracy, max_accuracy_train, max_time]) : {}\n",
      "\n",
      "\n",
      "\n",
      "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
      "Weighted accuracy is 0.9009999999999999 when alpha and k-folds are (3, 20) respectively.\n",
      "\n",
      "Accuracy on test data is: 0.902, averaged accuracy on train data is: 0.8910000000000001\n",
      "This took 18 seconds to solve.\n",
      "\n",
      "\n",
      "**The best overall accuracy on test data is so far standing at: 0.9079402390438247 when alpha and k-folds are (0.1, 500)\n",
      "Modules with similar accuracy (if any) have the following hyperparameters (hyperparameters:[weight accuracy, accuracy, max_accuracy_train, max_time]) : {}\n",
      "\n",
      "\n",
      "\n",
      "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
      "Weighted accuracy is 0.9011111111111111 when alpha and k-folds are (3, 25) respectively.\n",
      "\n",
      "Accuracy on test data is: 0.902, averaged accuracy on train data is: 0.8900000000000003\n",
      "This took 19 seconds to solve.\n",
      "\n",
      "\n",
      "**The best overall accuracy on test data is so far standing at: 0.9079402390438247 when alpha and k-folds are (0.1, 500)\n",
      "Modules with similar accuracy (if any) have the following hyperparameters (hyperparameters:[weight accuracy, accuracy, max_accuracy_train, max_time]) : {}\n",
      "\n",
      "\n",
      "\n",
      "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
      "Weighted accuracy is 0.9016153846153846 when alpha and k-folds are (3, 50) respectively.\n",
      "\n",
      "Accuracy on test data is: 0.902, averaged accuracy on train data is: 0.892\n",
      "This took 19 seconds to solve.\n",
      "\n",
      "\n",
      "**The best overall accuracy on test data is so far standing at: 0.9079402390438247 when alpha and k-folds are (0.1, 500)\n",
      "Modules with similar accuracy (if any) have the following hyperparameters (hyperparameters:[weight accuracy, accuracy, max_accuracy_train, max_time]) : {}\n",
      "\n",
      "\n",
      "\n",
      "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
      "Weighted accuracy is 0.9036862745098039 when alpha and k-folds are (3, 100) respectively.\n",
      "\n",
      "Accuracy on test data is: 0.904, averaged accuracy on train data is: 0.8879999999999999\n",
      "This took 19 seconds to solve.\n",
      "\n",
      "\n",
      "**The best overall accuracy on test data is so far standing at: 0.9079402390438247 when alpha and k-folds are (0.1, 500)\n",
      "Modules with similar accuracy (if any) have the following hyperparameters (hyperparameters:[weight accuracy, accuracy, max_accuracy_train, max_time]) : {}\n",
      "\n",
      "\n",
      "\n",
      "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
      "Weighted accuracy is 0.9018910891089109 when alpha and k-folds are (3, 200) respectively.\n",
      "\n",
      "Accuracy on test data is: 0.902, averaged accuracy on train data is: 0.891\n",
      "This took 20 seconds to solve.\n",
      "\n",
      "\n",
      "**The best overall accuracy on test data is so far standing at: 0.9079402390438247 when alpha and k-folds are (0.1, 500)\n",
      "Modules with similar accuracy (if any) have the following hyperparameters (hyperparameters:[weight accuracy, accuracy, max_accuracy_train, max_time]) : {}\n",
      "\n",
      "\n",
      "\n",
      "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
      "Weighted accuracy is 0.9059482071713147 when alpha and k-folds are (3, 500) respectively.\n",
      "\n",
      "Accuracy on test data is: 0.906, averaged accuracy on train data is: 0.893\n",
      "This took 20 seconds to solve.\n",
      "\n",
      "\n",
      "**The best overall accuracy on test data is so far standing at: 0.9079402390438247 when alpha and k-folds are (0.1, 500)\n",
      "Modules with similar accuracy (if any) have the following hyperparameters (hyperparameters:[weight accuracy, accuracy, max_accuracy_train, max_time]) : {}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "When alpha and k-folds are (0.1, 500) respectively, the expected overall weighted accuracy on unseen data is: 0.9079402390438247\n",
      "This module is 0.908 accurat on test data\n",
      "Whereas, averaged accuracy on train data is 0.893, and topped at 0.904\n",
      "This module takes 3 seconds to solve.\n",
      "Modules with similar accuracy (if any) have the following hyperparameters (hyperparameters:[weight accuracy, accuracy, max_accuracy_train, max_time]) : {}\n"
     ]
    }
   ],
   "source": [
    "#_naivebayes|selecting_hyperparameters\n",
    "import numpy as np\n",
    "import itertools\n",
    "import time \n",
    "\n",
    "start_time = time.process_time()\n",
    "\n",
    "training_spam = np.loadtxt(open(\"data/training_spam.csv\"), delimiter=\",\").astype(int)\n",
    "testing_spam = np.loadtxt(open(\"data/testing_spam.csv\"), delimiter=\",\").astype(int)\n",
    "\n",
    "class SpamClassifier: \n",
    "    def __init__(self, training_data, alpha=1):\n",
    "        self.alpha = alpha\n",
    "        self.training_data = training_data\n",
    "        \n",
    "    def train(self):\n",
    "        self.log_class_priors = SpamClassifier.estimate_log_class_priors(self.training_data)\n",
    "        self.log_class_conditional_likelihoods = SpamClassifier.estimate_log_class_conditional_likelihoods(self.training_data, self.alpha)\n",
    "        \n",
    "    @staticmethod\n",
    "    def estimate_log_class_priors(data):\n",
    "        data_labels = data[:, 0]\n",
    "        log_p_0 = np.log(np.where(data_labels==0)[0].shape[0]/len(data_labels))\n",
    "        log_p_1 = np.log(np.where(data_labels==1)[0].shape[0]/len(data_labels))\n",
    "        log_class_priors = np.array([log_p_0, log_p_1])\n",
    "        return log_class_priors\n",
    "    \n",
    "    @staticmethod\n",
    "    def estimate_log_class_conditional_likelihoods(data, alpha=1.0):\n",
    "        n_c_0 =  np.count_nonzero(data[:,1:][data[:,0]==0])\n",
    "        n_c_1 =  np.count_nonzero(data[:,1:][data[:,0]==1])\n",
    "        k = data.shape[1]-1\n",
    "        n_c_w = np.zeros(shape=(2,training_spam.shape[1]-1))\n",
    "        for i in range(1,training_spam.shape[1]):\n",
    "            n_c_w[0,i-1] = training_spam[training_spam[:,0]==0][training_spam[training_spam[:,0]==0][:,i]==1].shape[0]\n",
    "            n_c_w[1,i-1] = training_spam[training_spam[:,0]==1][training_spam[training_spam[:,0]==1][:,i]==1].shape[0]\n",
    "        theta = np.full_like(n_c_w, 0)\n",
    "        theta[0,:] = np.log((n_c_w[0,:] + alpha) / (n_c_0 + k*alpha))\n",
    "        theta[1,:] = np.log((n_c_w[1,:] + alpha) / (n_c_1 + k*alpha))\n",
    "        return theta\n",
    "\n",
    "\n",
    "    def predict(self, new_data):\n",
    "        class_predictions=np.zeros(shape=(new_data.shape[0]))\n",
    "        for i in range(new_data.shape[0]):\n",
    "            c_hat_0 = self.log_class_priors[0]+ np.sum(np.dot(new_data[i], self.log_class_conditional_likelihoods[0]))\n",
    "            c_hat_1 = self.log_class_priors[1]+ np.sum(np.dot(new_data[i], self.log_class_conditional_likelihoods[1]))\n",
    "            if c_hat_0>c_hat_1: \n",
    "                class_predictions[i]=0\n",
    "            else: \n",
    "                class_predictions[i]=1\n",
    "        return class_predictions\n",
    "\n",
    "\n",
    "def cross_validation(training_spam, item):\n",
    "    max_accuracy = 0\n",
    "    averaged_accuracy = 0\n",
    "    alpha, k_fold=item\n",
    "    x_training= training_spam[:,1:]\n",
    "    y_training= training_spam[:,0]\n",
    "    x = np.split(x_training, x_training.shape[0]/k_fold, axis=0)\n",
    "    y = np.split(y_training, y_training.shape[0]/k_fold, axis=0)\n",
    "    for i in range(len(x)):\n",
    "        x_temp=np.concatenate(x[0:i]+x[i+1:])\n",
    "        y_temp=np.concatenate(y[0:i]+y[i+1:])\n",
    "        y_temp=y_temp.reshape(y_temp.shape[0],1)\n",
    "        temp_data = np.concatenate((y_temp,x_temp), axis=1)\n",
    "        classifier = SpamClassifier(temp_data,alpha)\n",
    "        classifier.train()\n",
    "        final_y_predict_temp = classifier.predict(x[i])\n",
    "        accuracy = np.count_nonzero(final_y_predict_temp == y[i].reshape(final_y_predict_temp.shape))/final_y_predict_temp.shape[0]\n",
    "        \n",
    "        if accuracy > max_accuracy:\n",
    "            max_accuracy = accuracy\n",
    "            max_classifier= classifier\n",
    "            max_fold = i\n",
    "        averaged_accuracy += accuracy\n",
    "    averaged_accuracy = averaged_accuracy/len(x)\n",
    "    return max_classifier, max_fold, max_accuracy, averaged_accuracy\n",
    "\n",
    "def create_classifier(training_spam, item):\n",
    "    classifier = cross_validation(training_spam, item)\n",
    "    return classifier\n",
    "\n",
    "alpha_O = [0.1, 1, 1.5, 2, 2.5, 3]\n",
    "k_fold = [10,20,25, 50, 100, 200, 500]\n",
    "output_list = list(itertools.product(alpha_O, k_fold))\n",
    "max_weighted_accuracy=0\n",
    "for item in output_list:\n",
    "    \n",
    "    classifier, max_fold, max_accuracy_train, averaged_accuracy_train = create_classifier(training_spam, item)\n",
    "    end_time = time.process_time()\n",
    "    \n",
    "    test_data = testing_spam[:, 1:]\n",
    "    test_labels = testing_spam[:, 0]\n",
    "\n",
    "    predictions = classifier.predict(test_data)\n",
    "    accuracy = np.count_nonzero(predictions == test_labels)/test_labels.shape[0]\n",
    "    \n",
    "    \n",
    "    \n",
    "    weighted_accuracy = accuracy * test_data.shape[0] / (test_data.shape[0]+(training_spam.shape[0]/item[-1])) \\\n",
    "    + averaged_accuracy_train * (training_spam.shape[0]/item[-1]) / (test_data.shape[0]+(training_spam.shape[0]/item[-1]))\n",
    "    \n",
    "\n",
    "    if weighted_accuracy > max_weighted_accuracy:\n",
    "            dic={}\n",
    "            \n",
    "            max_weighted_accuracy=weighted_accuracy\n",
    "            max_accuracy = accuracy\n",
    "            maxi_accuracy_train = max_accuracy_train\n",
    "            averaged_accuracy_train = averaged_accuracy_train\n",
    "        \n",
    "            max_item = item\n",
    "            \n",
    "            max_time = int(end_time-start_time)\n",
    "    elif weighted_accuracy == max_weighted_accuracy:\n",
    "        dic[item]=[weighted_accuracy, accuracy, averaged_accuracy_train, max_accuracy_train]\n",
    "        \n",
    "         \n",
    "    print(\"&&\"*50)\n",
    "    print(f\"Weighted accuracy is {weighted_accuracy} when alpha and k-folds are {item} respectively.\")\n",
    "    print()\n",
    "    print(f\"Accuracy on test data is: {accuracy}, averaged accuracy on train data is: {averaged_accuracy_train}\")\n",
    "    print(f\"This took\", int(end_time-start_time), \"seconds to solve.\")\n",
    "    print()\n",
    "    print()\n",
    "    print(f\"**The best overall accuracy on test data is so far standing at: {max_weighted_accuracy} when alpha and k-folds are {max_item}\")\n",
    "    print(f\"Modules with similar accuracy (if any) have the following hyperparameters (hyperparameters:[weight accuracy, accuracy, max_accuracy_train, max_time]) : {dic}\")\n",
    "    print()\n",
    "    print()\n",
    "    print()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print()\n",
    "print('^'*250)\n",
    "print(f\"When alpha and k-folds are {max_item} respectively, the expected overall weighted accuracy on unseen data is: {max_weighted_accuracy}\")\n",
    "print(f\"This module is {max_accuracy} accurat on test data\")\n",
    "print(f\"Whereas, averaged accuracy on train data is {averaged_accuracy_train}, and topped at {maxi_accuracy_train}\")\n",
    "print(f\"This module takes {max_time} seconds to solve.\")\n",
    "print(f\"Modules with similar accuracy (if any) have the following hyperparameters (hyperparameters:[weight accuracy, accuracy, max_accuracy_train, max_time]) : {dic}\")\n",
    "\n",
    "# pass on the result to the final module below\n",
    "alpha, k_fold = max_item"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0ede49",
   "metadata": {},
   "source": [
    "#  Final Module \n",
    "\n",
    "When plugging the hyper parameters associated with the best average weighted accuracy I got when running the above code, I got a **0.908** accuracy when run on test data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "911c8fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#_naivebayes\n",
    "class SpamClassifier: \n",
    "    def __init__(self, training_data, alpha=1):\n",
    "        self.alpha = alpha\n",
    "        self.training_data = training_data\n",
    "        \n",
    "    def train(self):\n",
    "        self.log_class_priors = SpamClassifier.estimate_log_class_priors(self.training_data)\n",
    "        self.log_class_conditional_likelihoods = SpamClassifier.estimate_log_class_conditional_likelihoods(self.training_data, self.alpha)\n",
    "        \n",
    "    @staticmethod\n",
    "    def estimate_log_class_priors(data):\n",
    "        data_labels = data[:, 0]\n",
    "        log_p_0 = np.log(np.where(data_labels==0)[0].shape[0]/len(data_labels))\n",
    "        log_p_1 = np.log(np.where(data_labels==1)[0].shape[0]/len(data_labels))\n",
    "        log_class_priors = np.array([log_p_0, log_p_1])\n",
    "        return log_class_priors\n",
    "    \n",
    "    @staticmethod\n",
    "    def estimate_log_class_conditional_likelihoods(data, alpha=1.0):\n",
    "        n_c_0 =  np.count_nonzero(data[:,1:][data[:,0]==0])\n",
    "        n_c_1 =  np.count_nonzero(data[:,1:][data[:,0]==1])\n",
    "        k = data.shape[1]-1\n",
    "        n_c_w = np.zeros(shape=(2,training_spam.shape[1]-1))\n",
    "        for i in range(1,training_spam.shape[1]):\n",
    "            n_c_w[0,i-1] = training_spam[training_spam[:,0]==0][training_spam[training_spam[:,0]==0][:,i]==1].shape[0]\n",
    "            n_c_w[1,i-1] = training_spam[training_spam[:,0]==1][training_spam[training_spam[:,0]==1][:,i]==1].shape[0]\n",
    "        theta = np.full_like(n_c_w, 0)\n",
    "        theta[0,:] = np.log((n_c_w[0,:] + alpha) / (n_c_0 + k*alpha))\n",
    "        theta[1,:] = np.log((n_c_w[1,:] + alpha) / (n_c_1 + k*alpha))\n",
    "        return theta\n",
    "\n",
    "\n",
    "    def predict(self, new_data):\n",
    "        class_predictions=np.zeros(shape=(new_data.shape[0]))\n",
    "        for i in range(new_data.shape[0]):\n",
    "            c_hat_0 = self.log_class_priors[0]+ np.sum(np.dot(new_data[i], self.log_class_conditional_likelihoods[0]))\n",
    "            c_hat_1 = self.log_class_priors[1]+ np.sum(np.dot(new_data[i], self.log_class_conditional_likelihoods[1]))\n",
    "            if c_hat_0>c_hat_1: \n",
    "                class_predictions[i]=0\n",
    "            else: \n",
    "                class_predictions[i]=1\n",
    "\n",
    "        return class_predictions\n",
    "    \n",
    "def cross_validation(training_spam):\n",
    "    \n",
    "    x_training= training_spam[:,1:]\n",
    "    y_training= training_spam[:,0]\n",
    "    x = np.split(x_training, x_training.shape[0]/k_fold, axis=0)\n",
    "    y = np.split(y_training, y_training.shape[0]/k_fold, axis=0)\n",
    "    \n",
    "    max_accuracy = 0\n",
    "    averaged_accuracy = 0\n",
    "    for i in range(len(x)):\n",
    "        x_temp=np.concatenate(x[0:i]+x[i+1:])\n",
    "        y_temp=np.concatenate(y[0:i]+y[i+1:])\n",
    "        y_temp=y_temp.reshape(y_temp.shape[0],1)\n",
    "        temp_data = np.concatenate((y_temp,x_temp), axis=1)\n",
    "        classifier = SpamClassifier(temp_data,alpha)\n",
    "        classifier.train()\n",
    "        final_y_predict_temp = classifier.predict(x[i])\n",
    "        accuracy = np.count_nonzero(final_y_predict_temp == y[i].reshape(final_y_predict_temp.shape))/final_y_predict_temp.shape[0]\n",
    "        \n",
    "        if accuracy > max_accuracy:\n",
    "            max_accuracy = accuracy\n",
    "            max_classifier= classifier\n",
    "            max_fold = i\n",
    "        \n",
    "    return max_classifier\n",
    "\n",
    "def create_classifier(training_spam):\n",
    "    classifier = cross_validation(training_spam)\n",
    "    return classifier\n",
    "\n",
    "\n",
    "\n",
    "classifier = create_classifier(training_spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b2e1b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test data is: 0.908\n"
     ]
    }
   ],
   "source": [
    "# run on test data\n",
    "testing_spam = np.loadtxt(open(\"data/testing_spam.csv\"), delimiter=\",\").astype(int)\n",
    "test_data = testing_spam[:, 1:]\n",
    "test_labels = testing_spam[:, 0]\n",
    "\n",
    "predictions = classifier.predict(test_data)\n",
    "accuracy = np.count_nonzero(predictions == test_labels)/test_labels.shape[0]\n",
    "print(f\"Accuracy on test data is: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e398cbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     ___Confusion Matrix and Statistics___                      \n",
      "                   *****************************************                    \n",
      "\n",
      "           Reference   \n",
      "Prediction   0    1\n",
      "  0        276    25\n",
      "  1        21    178\n",
      "\n",
      "\n",
      "\n",
      "         Precision   Recall  f1-score   Support  \n",
      "      0  0.93        0.92    0.92       301\n",
      "      1  0.88        0.89    0.89        199\n",
      "\n",
      "accuracy                     0.908      500\n"
     ]
    }
   ],
   "source": [
    "def confusion_matrix(test_labels, predictions):\n",
    "    tp = tn = fp = fn = 0\n",
    "    for actual_value, predicted_value in zip(test_labels, predictions):\n",
    "        if predicted_value == actual_value:\n",
    "            if predicted_value == 1: \n",
    "                tp += 1\n",
    "            else: \n",
    "                tn += 1\n",
    "        else: \n",
    "            if predicted_value == 1:\n",
    "                fp += 1\n",
    "            else: \n",
    "                fn += 1\n",
    "    confusion_matrix = np.array([[tn, fp], [fn, tp]])\n",
    "    print('___Confusion Matrix and Statistics___'.center(80))\n",
    "    print('*****************************************'.center(80))\n",
    "    print()\n",
    "    print('           Reference   ')\n",
    "    print ('Prediction   0    1')\n",
    "    print('  0       ', confusion_matrix[0, 0],'  ',  confusion_matrix[0, 1])\n",
    "    print('  1       ', confusion_matrix[1, 0], '  ', confusion_matrix[1, 1])\n",
    "    \n",
    "    \n",
    "    accuracy = (tn+tp) / test_labels.shape[0]\n",
    "    print()\n",
    "    precision_positive =  tp / (tp+fp)\n",
    "    precision_negative = tn / (tn+fn)\n",
    "    recall_positive =  tp/ (tp+fn)\n",
    "    recall_negative = tn/ (tn+fp)\n",
    "    \n",
    "    f1_positive = 2*(precision_positive * recall_positive)/(precision_positive+recall_positive)\n",
    "    f1_negative = 2*(precision_negative * recall_negative)/(precision_negative+recall_negative)\n",
    "    print()\n",
    "    print()\n",
    "    print('         Precision   Recall  f1-score   Support  ')\n",
    "    print ('      0 ', np.round(precision_negative,2),'      ', np.round(recall_negative,2),'  ', np.round(f1_negative,2), '     ', tn+fp )\n",
    "    print ('      1 ', np.round(precision_positive,2),'      ', np.round(recall_positive,2), '  ', np.round(f1_positive,2),'      ', tp+fn )\n",
    "    print()\n",
    "    print('accuracy                    ', accuracy,'    ',test_labels.shape[0] )\n",
    "\n",
    "confusion_matrix(test_labels, predictions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7326a552",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
