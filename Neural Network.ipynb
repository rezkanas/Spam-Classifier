{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07abc1ef",
   "metadata": {},
   "source": [
    "# Selecting Nerual Network's Hyperparameters:\n",
    " I have considered here multiple combinations of:\n",
    "   * **Number of Hidden Layers** \n",
    "   * **Number of Neurons** \n",
    "   * **Learning Rate:** is a constant that determine how rapidly we progress toward the minimum of our cost function.\n",
    "   * **Number of Epoc:**  number of times an ENTIRE dataset is passed forward and backward through the neural network.  \n",
    "   * **Error Margin:**  is the margin between cost function between current and previous modules during gradient descent.\n",
    "   * **Regularization Parameter:** is a constant that reduces the values of particular weights. This is introduced in order to reduce the problem of overfitting \n",
    "   * **Number Fold** is the numbers of foldes that training data are split into. This is used in cross valdiation excercise. \n",
    "\n",
    "I plug a serie of combinations in `create_classifier` in order to measure the weighted overall accuracy on unseen data. I, then, select the hyperparameters that got the best accuracy to go into the final module that I used for prediction on test data.  \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1397c20",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
      "Weighted accuracy is 0.841 when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_folds are (3, [3, 4, 2], 0.001, 10000, 1e-06, 1, 200) respectively.\n",
      "\n",
      "Accuracy on test data is: 0.918, averaged accuracy on train data is: 0.8019999999999999 after 10000 epoc\n",
      "This took 583 seconds to solve.\n",
      "\n",
      "\n",
      "**The best overall accuracy on test data is so far standing at: 0.841 when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_fold are (3, [3, 4, 2], 0.001, 10000, 1e-06, 1, 200)\n",
      "**Modules with similar accuracy (if any) have the following hyperparameters (hyperparameters:[weight accuracy, averaged_accuracy_train ,max_accuracy_train, max_time]) : {}\n",
      "\n",
      "\n",
      "\n",
      "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
      "Weighted accuracy is 0.921 when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_folds are (3, [3, 4, 2], 0.001, 10000, 1e-06, 2, 200) respectively.\n",
      "\n",
      "Accuracy on test data is: 0.928, averaged accuracy on train data is: 0.915 after 10000 epoc\n",
      "This took 1212 seconds to solve.\n",
      "\n",
      "\n",
      "**The best overall accuracy on test data is so far standing at: 0.921 when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_fold are (3, [3, 4, 2], 0.001, 10000, 1e-06, 2, 200)\n",
      "**Modules with similar accuracy (if any) have the following hyperparameters (hyperparameters:[weight accuracy, averaged_accuracy_train ,max_accuracy_train, max_time]) : {}\n",
      "\n",
      "\n",
      "\n",
      "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
      "Weighted accuracy is 0.927 when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_folds are (3, [3, 4, 2], 0.001, 10000, 1e-06, 3, 200) respectively.\n",
      "\n",
      "Accuracy on test data is: 0.93, averaged accuracy on train data is: 0.922 after 10000 epoc\n",
      "This took 1853 seconds to solve.\n",
      "\n",
      "\n",
      "**The best overall accuracy on test data is so far standing at: 0.927 when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_fold are (3, [3, 4, 2], 0.001, 10000, 1e-06, 3, 200)\n",
      "**Modules with similar accuracy (if any) have the following hyperparameters (hyperparameters:[weight accuracy, averaged_accuracy_train ,max_accuracy_train, max_time]) : {}\n",
      "\n",
      "\n",
      "\n",
      "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
      "Weighted accuracy is 0.877 when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_folds are (3, [3, 4, 2], 0.001, 10000, 1e-07, 1, 200) respectively.\n",
      "\n",
      "Accuracy on test data is: 0.92, averaged accuracy on train data is: 0.8550000000000001 after 10000 epoc\n",
      "This took 2439 seconds to solve.\n",
      "\n",
      "\n",
      "**The best overall accuracy on test data is so far standing at: 0.927 when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_fold are (3, [3, 4, 2], 0.001, 10000, 1e-06, 3, 200)\n",
      "**Modules with similar accuracy (if any) have the following hyperparameters (hyperparameters:[weight accuracy, averaged_accuracy_train ,max_accuracy_train, max_time]) : {}\n",
      "\n",
      "\n",
      "\n",
      "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
      "Weighted accuracy is 0.92 when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_folds are (3, [3, 4, 2], 0.001, 10000, 1e-07, 2, 200) respectively.\n",
      "\n",
      "Accuracy on test data is: 0.922, averaged accuracy on train data is: 0.9179999999999999 after 10000 epoc\n",
      "This took 3110 seconds to solve.\n",
      "\n",
      "\n",
      "**The best overall accuracy on test data is so far standing at: 0.927 when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_fold are (3, [3, 4, 2], 0.001, 10000, 1e-06, 3, 200)\n",
      "**Modules with similar accuracy (if any) have the following hyperparameters (hyperparameters:[weight accuracy, averaged_accuracy_train ,max_accuracy_train, max_time]) : {}\n",
      "\n",
      "\n",
      "\n",
      "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
      "Weighted accuracy is 0.926 when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_folds are (3, [3, 4, 2], 0.001, 10000, 1e-07, 3, 200) respectively.\n",
      "\n",
      "Accuracy on test data is: 0.93, averaged accuracy on train data is: 0.9190000000000002 after 10000 epoc\n",
      "This took 3797 seconds to solve.\n",
      "\n",
      "\n",
      "**The best overall accuracy on test data is so far standing at: 0.927 when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_fold are (3, [3, 4, 2], 0.001, 10000, 1e-06, 3, 200)\n",
      "**Modules with similar accuracy (if any) have the following hyperparameters (hyperparameters:[weight accuracy, averaged_accuracy_train ,max_accuracy_train, max_time]) : {}\n",
      "\n",
      "\n",
      "\n",
      "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
      "Weighted accuracy is 0.837 when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_folds are (3, [3, 4, 2], 0.001, 15000, 1e-06, 1, 200) respectively.\n",
      "\n",
      "Accuracy on test data is: 0.926, averaged accuracy on train data is: 0.7919999999999999 after 15000 epoc\n",
      "This took 4771 seconds to solve.\n",
      "\n",
      "\n",
      "**The best overall accuracy on test data is so far standing at: 0.927 when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_fold are (3, [3, 4, 2], 0.001, 10000, 1e-06, 3, 200)\n",
      "**Modules with similar accuracy (if any) have the following hyperparameters (hyperparameters:[weight accuracy, averaged_accuracy_train ,max_accuracy_train, max_time]) : {}\n",
      "\n",
      "\n",
      "\n",
      "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
      "Weighted accuracy is 0.915 when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_folds are (3, [3, 4, 2], 0.001, 15000, 1e-06, 2, 200) respectively.\n",
      "\n",
      "Accuracy on test data is: 0.926, averaged accuracy on train data is: 0.905 after 3349 epoc\n",
      "This took 5615 seconds to solve.\n",
      "\n",
      "\n",
      "**The best overall accuracy on test data is so far standing at: 0.927 when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_fold are (3, [3, 4, 2], 0.001, 10000, 1e-06, 3, 200)\n",
      "**Modules with similar accuracy (if any) have the following hyperparameters (hyperparameters:[weight accuracy, averaged_accuracy_train ,max_accuracy_train, max_time]) : {}\n",
      "\n",
      "\n",
      "\n",
      "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
      "Weighted accuracy is 0.899 when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_folds are (3, [3, 4, 2], 0.001, 15000, 1e-06, 3, 200) respectively.\n",
      "\n",
      "Accuracy on test data is: 0.928, averaged accuracy on train data is: 0.8560000000000001 after 15000 epoc\n",
      "This took 6433 seconds to solve.\n",
      "\n",
      "\n",
      "**The best overall accuracy on test data is so far standing at: 0.927 when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_fold are (3, [3, 4, 2], 0.001, 10000, 1e-06, 3, 200)\n",
      "**Modules with similar accuracy (if any) have the following hyperparameters (hyperparameters:[weight accuracy, averaged_accuracy_train ,max_accuracy_train, max_time]) : {}\n",
      "\n",
      "\n",
      "\n",
      "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
      "Weighted accuracy is 0.912 when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_folds are (3, [3, 4, 2], 0.001, 15000, 1e-07, 1, 200) respectively.\n",
      "\n",
      "Accuracy on test data is: 0.92, averaged accuracy on train data is: 0.908 after 15000 epoc\n",
      "This took 7320 seconds to solve.\n",
      "\n",
      "\n",
      "**The best overall accuracy on test data is so far standing at: 0.927 when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_fold are (3, [3, 4, 2], 0.001, 10000, 1e-06, 3, 200)\n",
      "**Modules with similar accuracy (if any) have the following hyperparameters (hyperparameters:[weight accuracy, averaged_accuracy_train ,max_accuracy_train, max_time]) : {}\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
      "Weighted accuracy is 0.921 when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_folds are (3, [3, 4, 2], 0.001, 15000, 1e-07, 2, 200) respectively.\n",
      "\n",
      "Accuracy on test data is: 0.928, averaged accuracy on train data is: 0.913 after 15000 epoc\n",
      "This took 8202 seconds to solve.\n",
      "\n",
      "\n",
      "**The best overall accuracy on test data is so far standing at: 0.927 when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_fold are (3, [3, 4, 2], 0.001, 10000, 1e-06, 3, 200)\n",
      "**Modules with similar accuracy (if any) have the following hyperparameters (hyperparameters:[weight accuracy, averaged_accuracy_train ,max_accuracy_train, max_time]) : {}\n",
      "\n",
      "\n",
      "\n",
      "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
      "Weighted accuracy is 0.902 when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_folds are (3, [3, 4, 2], 0.001, 15000, 1e-07, 3, 200) respectively.\n",
      "\n",
      "Accuracy on test data is: 0.928, averaged accuracy on train data is: 0.8640000000000001 after 2396 epoc\n",
      "This took 8986 seconds to solve.\n",
      "\n",
      "\n",
      "**The best overall accuracy on test data is so far standing at: 0.927 when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_fold are (3, [3, 4, 2], 0.001, 10000, 1e-06, 3, 200)\n",
      "**Modules with similar accuracy (if any) have the following hyperparameters (hyperparameters:[weight accuracy, averaged_accuracy_train ,max_accuracy_train, max_time]) : {}\n",
      "\n",
      "\n",
      "\n",
      "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
      "Weighted accuracy is 0.84 when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_folds are (3, [3, 4, 2], 0.01, 10000, 1e-06, 1, 200) respectively.\n",
      "\n",
      "Accuracy on test data is: 0.92, averaged accuracy on train data is: 0.8 after 10000 epoc\n",
      "This took 9378 seconds to solve.\n",
      "\n",
      "\n",
      "**The best overall accuracy on test data is so far standing at: 0.927 when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_fold are (3, [3, 4, 2], 0.001, 10000, 1e-06, 3, 200)\n",
      "**Modules with similar accuracy (if any) have the following hyperparameters (hyperparameters:[weight accuracy, averaged_accuracy_train ,max_accuracy_train, max_time]) : {}\n",
      "\n",
      "\n",
      "\n",
      "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
      "Weighted accuracy is 0.607 when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_folds are (3, [3, 4, 2], 0.01, 10000, 1e-06, 2, 200) respectively.\n",
      "\n",
      "Accuracy on test data is: 0.602, averaged accuracy on train data is: 0.613 after 459 epoc\n",
      "This took 9405 seconds to solve.\n",
      "\n",
      "\n",
      "**The best overall accuracy on test data is so far standing at: 0.927 when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_fold are (3, [3, 4, 2], 0.001, 10000, 1e-06, 3, 200)\n",
      "**Modules with similar accuracy (if any) have the following hyperparameters (hyperparameters:[weight accuracy, averaged_accuracy_train ,max_accuracy_train, max_time]) : {}\n",
      "\n",
      "\n",
      "\n",
      "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
      "Weighted accuracy is 0.606 when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_folds are (3, [3, 4, 2], 0.01, 10000, 1e-06, 3, 200) respectively.\n",
      "\n",
      "Accuracy on test data is: 0.602, averaged accuracy on train data is: 0.613 after 411 epoc\n",
      "This took 9427 seconds to solve.\n",
      "\n",
      "\n",
      "**The best overall accuracy on test data is so far standing at: 0.927 when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_fold are (3, [3, 4, 2], 0.001, 10000, 1e-06, 3, 200)\n",
      "**Modules with similar accuracy (if any) have the following hyperparameters (hyperparameters:[weight accuracy, averaged_accuracy_train ,max_accuracy_train, max_time]) : {}\n",
      "\n",
      "\n",
      "\n",
      "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
      "Weighted accuracy is 0.915 when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_folds are (3, [3, 4, 2], 0.01, 10000, 1e-07, 1, 200) respectively.\n",
      "\n",
      "Accuracy on test data is: 0.92, averaged accuracy on train data is: 0.913 after 10000 epoc\n",
      "This took 10067 seconds to solve.\n",
      "\n",
      "\n",
      "**The best overall accuracy on test data is so far standing at: 0.927 when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_fold are (3, [3, 4, 2], 0.001, 10000, 1e-06, 3, 200)\n",
      "**Modules with similar accuracy (if any) have the following hyperparameters (hyperparameters:[weight accuracy, averaged_accuracy_train ,max_accuracy_train, max_time]) : {}\n",
      "\n",
      "\n",
      "\n",
      "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
      "Weighted accuracy is 0.607 when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_folds are (3, [3, 4, 2], 0.01, 10000, 1e-07, 2, 200) respectively.\n",
      "\n",
      "Accuracy on test data is: 0.602, averaged accuracy on train data is: 0.613 after 625 epoc\n",
      "This took 10105 seconds to solve.\n",
      "\n",
      "\n",
      "**The best overall accuracy on test data is so far standing at: 0.927 when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_fold are (3, [3, 4, 2], 0.001, 10000, 1e-06, 3, 200)\n",
      "**Modules with similar accuracy (if any) have the following hyperparameters (hyperparameters:[weight accuracy, averaged_accuracy_train ,max_accuracy_train, max_time]) : {}\n",
      "\n",
      "\n",
      "\n",
      "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
      "Weighted accuracy is 0.606 when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_folds are (3, [3, 4, 2], 0.01, 10000, 1e-07, 3, 200) respectively.\n",
      "\n",
      "Accuracy on test data is: 0.602, averaged accuracy on train data is: 0.613 after 401 epoc\n",
      "This took 10131 seconds to solve.\n",
      "\n",
      "\n",
      "**The best overall accuracy on test data is so far standing at: 0.927 when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_fold are (3, [3, 4, 2], 0.001, 10000, 1e-06, 3, 200)\n",
      "**Modules with similar accuracy (if any) have the following hyperparameters (hyperparameters:[weight accuracy, averaged_accuracy_train ,max_accuracy_train, max_time]) : {}\n",
      "\n",
      "\n",
      "\n",
      "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
      "Weighted accuracy is 0.922 when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_folds are (3, [3, 4, 2], 0.01, 15000, 1e-06, 1, 200) respectively.\n",
      "\n",
      "Accuracy on test data is: 0.912, averaged accuracy on train data is: 0.9269999999999999 after 15000 epoc\n",
      "This took 11106 seconds to solve.\n",
      "\n",
      "\n",
      "**The best overall accuracy on test data is so far standing at: 0.927 when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_fold are (3, [3, 4, 2], 0.001, 10000, 1e-06, 3, 200)\n",
      "**Modules with similar accuracy (if any) have the following hyperparameters (hyperparameters:[weight accuracy, averaged_accuracy_train ,max_accuracy_train, max_time]) : {}\n",
      "\n",
      "\n",
      "\n",
      "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
      "Weighted accuracy is 0.607 when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_folds are (3, [3, 4, 2], 0.01, 15000, 1e-06, 2, 200) respectively.\n",
      "\n",
      "Accuracy on test data is: 0.602, averaged accuracy on train data is: 0.613 after 411 epoc\n",
      "This took 11134 seconds to solve.\n",
      "\n",
      "\n",
      "**The best overall accuracy on test data is so far standing at: 0.927 when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_fold are (3, [3, 4, 2], 0.001, 10000, 1e-06, 3, 200)\n",
      "**Modules with similar accuracy (if any) have the following hyperparameters (hyperparameters:[weight accuracy, averaged_accuracy_train ,max_accuracy_train, max_time]) : {}\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
      "Weighted accuracy is 0.606 when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_folds are (3, [3, 4, 2], 0.01, 15000, 1e-06, 3, 200) respectively.\n",
      "\n",
      "Accuracy on test data is: 0.602, averaged accuracy on train data is: 0.613 after 332 epoc\n",
      "This took 11156 seconds to solve.\n",
      "\n",
      "\n",
      "**The best overall accuracy on test data is so far standing at: 0.927 when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_fold are (3, [3, 4, 2], 0.001, 10000, 1e-06, 3, 200)\n",
      "**Modules with similar accuracy (if any) have the following hyperparameters (hyperparameters:[weight accuracy, averaged_accuracy_train ,max_accuracy_train, max_time]) : {}\n",
      "\n",
      "\n",
      "\n",
      "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
      "Weighted accuracy is 0.913 when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_folds are (3, [3, 4, 2], 0.01, 15000, 1e-07, 1, 200) respectively.\n",
      "\n",
      "Accuracy on test data is: 0.91, averaged accuracy on train data is: 0.914 after 15000 epoc\n",
      "This took 12126 seconds to solve.\n",
      "\n",
      "\n",
      "**The best overall accuracy on test data is so far standing at: 0.927 when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_fold are (3, [3, 4, 2], 0.001, 10000, 1e-06, 3, 200)\n",
      "**Modules with similar accuracy (if any) have the following hyperparameters (hyperparameters:[weight accuracy, averaged_accuracy_train ,max_accuracy_train, max_time]) : {}\n",
      "\n",
      "\n",
      "\n",
      "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
      "Weighted accuracy is 0.792 when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_folds are (3, [3, 4, 2], 0.01, 15000, 1e-07, 2, 200) respectively.\n",
      "\n",
      "Accuracy on test data is: 0.9, averaged accuracy on train data is: 0.683 after 512 epoc\n",
      "This took 12344 seconds to solve.\n",
      "\n",
      "\n",
      "**The best overall accuracy on test data is so far standing at: 0.927 when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_fold are (3, [3, 4, 2], 0.001, 10000, 1e-06, 3, 200)\n",
      "**Modules with similar accuracy (if any) have the following hyperparameters (hyperparameters:[weight accuracy, averaged_accuracy_train ,max_accuracy_train, max_time]) : {}\n",
      "\n",
      "\n",
      "\n",
      "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
      "Weighted accuracy is 0.606 when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_folds are (3, [3, 4, 2], 0.01, 15000, 1e-07, 3, 200) respectively.\n",
      "\n",
      "Accuracy on test data is: 0.602, averaged accuracy on train data is: 0.613 after 457 epoc\n",
      "This took 12370 seconds to solve.\n",
      "\n",
      "\n",
      "**The best overall accuracy on test data is so far standing at: 0.927 when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_fold are (3, [3, 4, 2], 0.001, 10000, 1e-06, 3, 200)\n",
      "**Modules with similar accuracy (if any) have the following hyperparameters (hyperparameters:[weight accuracy, averaged_accuracy_train ,max_accuracy_train, max_time]) : {}\n",
      "\n",
      "\n",
      "\n",
      "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
      "Weighted accuracy is 0.609 when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_folds are (3, [3, 4, 2], 0.1, 10000, 1e-06, 1, 200) respectively.\n",
      "\n",
      "Accuracy on test data is: 0.602, averaged accuracy on train data is: 0.613 after 103 epoc\n",
      "This took 12376 seconds to solve.\n",
      "\n",
      "\n",
      "**The best overall accuracy on test data is so far standing at: 0.927 when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_fold are (3, [3, 4, 2], 0.001, 10000, 1e-06, 3, 200)\n",
      "**Modules with similar accuracy (if any) have the following hyperparameters (hyperparameters:[weight accuracy, averaged_accuracy_train ,max_accuracy_train, max_time]) : {}\n",
      "\n",
      "\n",
      "\n",
      "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
      "Weighted accuracy is 0.607 when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_folds are (3, [3, 4, 2], 0.1, 10000, 1e-06, 2, 200) respectively.\n",
      "\n",
      "Accuracy on test data is: 0.602, averaged accuracy on train data is: 0.613 after 66 epoc\n",
      "This took 12380 seconds to solve.\n",
      "\n",
      "\n",
      "**The best overall accuracy on test data is so far standing at: 0.927 when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_fold are (3, [3, 4, 2], 0.001, 10000, 1e-06, 3, 200)\n",
      "**Modules with similar accuracy (if any) have the following hyperparameters (hyperparameters:[weight accuracy, averaged_accuracy_train ,max_accuracy_train, max_time]) : {}\n",
      "\n",
      "\n",
      "\n",
      "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
      "Weighted accuracy is 0.606 when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_folds are (3, [3, 4, 2], 0.1, 10000, 1e-06, 3, 200) respectively.\n",
      "\n",
      "Accuracy on test data is: 0.602, averaged accuracy on train data is: 0.613 after 67 epoc\n",
      "This took 12385 seconds to solve.\n",
      "\n",
      "\n",
      "**The best overall accuracy on test data is so far standing at: 0.927 when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_fold are (3, [3, 4, 2], 0.001, 10000, 1e-06, 3, 200)\n",
      "**Modules with similar accuracy (if any) have the following hyperparameters (hyperparameters:[weight accuracy, averaged_accuracy_train ,max_accuracy_train, max_time]) : {}\n",
      "\n",
      "\n",
      "\n",
      "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
      "Weighted accuracy is 0.609 when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_folds are (3, [3, 4, 2], 0.1, 10000, 1e-07, 1, 200) respectively.\n",
      "\n",
      "Accuracy on test data is: 0.602, averaged accuracy on train data is: 0.613 after 113 epoc\n",
      "This took 12393 seconds to solve.\n",
      "\n",
      "\n",
      "**The best overall accuracy on test data is so far standing at: 0.927 when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_fold are (3, [3, 4, 2], 0.001, 10000, 1e-06, 3, 200)\n",
      "**Modules with similar accuracy (if any) have the following hyperparameters (hyperparameters:[weight accuracy, averaged_accuracy_train ,max_accuracy_train, max_time]) : {}\n",
      "\n",
      "\n",
      "\n",
      "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
      "Weighted accuracy is 0.607 when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_folds are (3, [3, 4, 2], 0.1, 10000, 1e-07, 2, 200) respectively.\n",
      "\n",
      "Accuracy on test data is: 0.602, averaged accuracy on train data is: 0.613 after 67 epoc\n",
      "This took 12397 seconds to solve.\n",
      "\n",
      "\n",
      "**The best overall accuracy on test data is so far standing at: 0.927 when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_fold are (3, [3, 4, 2], 0.001, 10000, 1e-06, 3, 200)\n",
      "**Modules with similar accuracy (if any) have the following hyperparameters (hyperparameters:[weight accuracy, averaged_accuracy_train ,max_accuracy_train, max_time]) : {}\n",
      "\n",
      "\n",
      "\n",
      "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
      "Weighted accuracy is 0.606 when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_folds are (3, [3, 4, 2], 0.1, 10000, 1e-07, 3, 200) respectively.\n",
      "\n",
      "Accuracy on test data is: 0.602, averaged accuracy on train data is: 0.613 after 107 epoc\n",
      "This took 12404 seconds to solve.\n",
      "\n",
      "\n",
      "**The best overall accuracy on test data is so far standing at: 0.927 when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_fold are (3, [3, 4, 2], 0.001, 10000, 1e-06, 3, 200)\n",
      "**Modules with similar accuracy (if any) have the following hyperparameters (hyperparameters:[weight accuracy, averaged_accuracy_train ,max_accuracy_train, max_time]) : {}\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
      "Weighted accuracy is 0.609 when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_folds are (3, [3, 4, 2], 0.1, 15000, 1e-06, 1, 200) respectively.\n",
      "\n",
      "Accuracy on test data is: 0.602, averaged accuracy on train data is: 0.613 after 106 epoc\n",
      "This took 12410 seconds to solve.\n",
      "\n",
      "\n",
      "**The best overall accuracy on test data is so far standing at: 0.927 when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_fold are (3, [3, 4, 2], 0.001, 10000, 1e-06, 3, 200)\n",
      "**Modules with similar accuracy (if any) have the following hyperparameters (hyperparameters:[weight accuracy, averaged_accuracy_train ,max_accuracy_train, max_time]) : {}\n",
      "\n",
      "\n",
      "\n",
      "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
      "Weighted accuracy is 0.607 when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_folds are (3, [3, 4, 2], 0.1, 15000, 1e-06, 2, 200) respectively.\n",
      "\n",
      "Accuracy on test data is: 0.602, averaged accuracy on train data is: 0.613 after 65 epoc\n",
      "This took 12414 seconds to solve.\n",
      "\n",
      "\n",
      "**The best overall accuracy on test data is so far standing at: 0.927 when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_fold are (3, [3, 4, 2], 0.001, 10000, 1e-06, 3, 200)\n",
      "**Modules with similar accuracy (if any) have the following hyperparameters (hyperparameters:[weight accuracy, averaged_accuracy_train ,max_accuracy_train, max_time]) : {}\n",
      "\n",
      "\n",
      "\n",
      "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
      "Weighted accuracy is 0.606 when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_folds are (3, [3, 4, 2], 0.1, 15000, 1e-06, 3, 200) respectively.\n",
      "\n",
      "Accuracy on test data is: 0.602, averaged accuracy on train data is: 0.613 after 88 epoc\n",
      "This took 12419 seconds to solve.\n",
      "\n",
      "\n",
      "**The best overall accuracy on test data is so far standing at: 0.927 when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_fold are (3, [3, 4, 2], 0.001, 10000, 1e-06, 3, 200)\n",
      "**Modules with similar accuracy (if any) have the following hyperparameters (hyperparameters:[weight accuracy, averaged_accuracy_train ,max_accuracy_train, max_time]) : {}\n",
      "\n",
      "\n",
      "\n",
      "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
      "Weighted accuracy is 0.609 when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_folds are (3, [3, 4, 2], 0.1, 15000, 1e-07, 1, 200) respectively.\n",
      "\n",
      "Accuracy on test data is: 0.602, averaged accuracy on train data is: 0.613 after 132 epoc\n",
      "This took 12427 seconds to solve.\n",
      "\n",
      "\n",
      "**The best overall accuracy on test data is so far standing at: 0.927 when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_fold are (3, [3, 4, 2], 0.001, 10000, 1e-06, 3, 200)\n",
      "**Modules with similar accuracy (if any) have the following hyperparameters (hyperparameters:[weight accuracy, averaged_accuracy_train ,max_accuracy_train, max_time]) : {}\n",
      "\n",
      "\n",
      "\n",
      "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
      "Weighted accuracy is 0.607 when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_folds are (3, [3, 4, 2], 0.1, 15000, 1e-07, 2, 200) respectively.\n",
      "\n",
      "Accuracy on test data is: 0.602, averaged accuracy on train data is: 0.613 after 66 epoc\n",
      "This took 12431 seconds to solve.\n",
      "\n",
      "\n",
      "**The best overall accuracy on test data is so far standing at: 0.927 when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_fold are (3, [3, 4, 2], 0.001, 10000, 1e-06, 3, 200)\n",
      "**Modules with similar accuracy (if any) have the following hyperparameters (hyperparameters:[weight accuracy, averaged_accuracy_train ,max_accuracy_train, max_time]) : {}\n",
      "\n",
      "\n",
      "\n",
      "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
      "Weighted accuracy is 0.606 when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_folds are (3, [3, 4, 2], 0.1, 15000, 1e-07, 3, 200) respectively.\n",
      "\n",
      "Accuracy on test data is: 0.602, averaged accuracy on train data is: 0.613 after 100 epoc\n",
      "This took 12437 seconds to solve.\n",
      "\n",
      "\n",
      "**The best overall accuracy on test data is so far standing at: 0.927 when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_fold are (3, [3, 4, 2], 0.001, 10000, 1e-06, 3, 200)\n",
      "**Modules with similar accuracy (if any) have the following hyperparameters (hyperparameters:[weight accuracy, averaged_accuracy_train ,max_accuracy_train, max_time]) : {}\n",
      "\n",
      "\n",
      "\n",
      "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
      "Weighted accuracy is 0.609 when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_folds are (3, [3, 4, 2], 1, 10000, 1e-06, 1, 200) respectively.\n",
      "\n",
      "Accuracy on test data is: 0.602, averaged accuracy on train data is: 0.613 after 19 epoc\n",
      "This took 12438 seconds to solve.\n",
      "\n",
      "\n",
      "**The best overall accuracy on test data is so far standing at: 0.927 when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_fold are (3, [3, 4, 2], 0.001, 10000, 1e-06, 3, 200)\n",
      "**Modules with similar accuracy (if any) have the following hyperparameters (hyperparameters:[weight accuracy, averaged_accuracy_train ,max_accuracy_train, max_time]) : {}\n",
      "\n",
      "\n",
      "\n",
      "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
      "Weighted accuracy is 0.607 when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_folds are (3, [3, 4, 2], 1, 10000, 1e-06, 2, 200) respectively.\n",
      "\n",
      "Accuracy on test data is: 0.602, averaged accuracy on train data is: 0.613 after 10000 epoc\n",
      "This took 13055 seconds to solve.\n",
      "\n",
      "\n",
      "**The best overall accuracy on test data is so far standing at: 0.927 when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_fold are (3, [3, 4, 2], 0.001, 10000, 1e-06, 3, 200)\n",
      "**Modules with similar accuracy (if any) have the following hyperparameters (hyperparameters:[weight accuracy, averaged_accuracy_train ,max_accuracy_train, max_time]) : {}\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-fdf23be20dc9>:123: RuntimeWarning: divide by zero encountered in log\n",
      "  return -(1/y.shape[0])* np.sum((y * np.log(y_predicted) + (1-y) * np.log(1-y_predicted))) + (self.regularization_parameter/ (2*y.shape[0]) * weights_summed)\n",
      "<ipython-input-1-fdf23be20dc9>:123: RuntimeWarning: invalid value encountered in multiply\n",
      "  return -(1/y.shape[0])* np.sum((y * np.log(y_predicted) + (1-y) * np.log(1-y_predicted))) + (self.regularization_parameter/ (2*y.shape[0]) * weights_summed)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
      "Weighted accuracy is 0.394 when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_folds are (3, [3, 4, 2], 1, 10000, 1e-06, 3, 200) respectively.\n",
      "\n",
      "Accuracy on test data is: 0.398, averaged accuracy on train data is: 0.38699999999999996 after 6 epoc\n",
      "This took 13055 seconds to solve.\n",
      "\n",
      "\n",
      "**The best overall accuracy on test data is so far standing at: 0.927 when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_fold are (3, [3, 4, 2], 0.001, 10000, 1e-06, 3, 200)\n",
      "**Modules with similar accuracy (if any) have the following hyperparameters (hyperparameters:[weight accuracy, averaged_accuracy_train ,max_accuracy_train, max_time]) : {}\n",
      "\n",
      "\n",
      "\n",
      "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
      "Weighted accuracy is 0.609 when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_folds are (3, [3, 4, 2], 1, 10000, 1e-07, 1, 200) respectively.\n",
      "\n",
      "Accuracy on test data is: 0.602, averaged accuracy on train data is: 0.613 after 20 epoc\n",
      "This took 13057 seconds to solve.\n",
      "\n",
      "\n",
      "**The best overall accuracy on test data is so far standing at: 0.927 when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_fold are (3, [3, 4, 2], 0.001, 10000, 1e-06, 3, 200)\n",
      "**Modules with similar accuracy (if any) have the following hyperparameters (hyperparameters:[weight accuracy, averaged_accuracy_train ,max_accuracy_train, max_time]) : {}\n",
      "\n",
      "\n",
      "\n",
      "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
      "Weighted accuracy is 0.607 when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_folds are (3, [3, 4, 2], 1, 10000, 1e-07, 2, 200) respectively.\n",
      "\n",
      "Accuracy on test data is: 0.602, averaged accuracy on train data is: 0.613 after 10000 epoc\n",
      "This took 13772 seconds to solve.\n",
      "\n",
      "\n",
      "**The best overall accuracy on test data is so far standing at: 0.927 when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_fold are (3, [3, 4, 2], 0.001, 10000, 1e-06, 3, 200)\n",
      "**Modules with similar accuracy (if any) have the following hyperparameters (hyperparameters:[weight accuracy, averaged_accuracy_train ,max_accuracy_train, max_time]) : {}\n",
      "\n",
      "\n",
      "\n",
      "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
      "Weighted accuracy is 0.394 when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_folds are (3, [3, 4, 2], 1, 10000, 1e-07, 3, 200) respectively.\n",
      "\n",
      "Accuracy on test data is: 0.398, averaged accuracy on train data is: 0.38699999999999996 after 6 epoc\n",
      "This took 13773 seconds to solve.\n",
      "\n",
      "\n",
      "**The best overall accuracy on test data is so far standing at: 0.927 when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_fold are (3, [3, 4, 2], 0.001, 10000, 1e-06, 3, 200)\n",
      "**Modules with similar accuracy (if any) have the following hyperparameters (hyperparameters:[weight accuracy, averaged_accuracy_train ,max_accuracy_train, max_time]) : {}\n",
      "\n",
      "\n",
      "\n",
      "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
      "Weighted accuracy is 0.609 when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_folds are (3, [3, 4, 2], 1, 15000, 1e-06, 1, 200) respectively.\n",
      "\n",
      "Accuracy on test data is: 0.602, averaged accuracy on train data is: 0.613 after 20 epoc\n",
      "This took 13774 seconds to solve.\n",
      "\n",
      "\n",
      "**The best overall accuracy on test data is so far standing at: 0.927 when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_fold are (3, [3, 4, 2], 0.001, 10000, 1e-06, 3, 200)\n",
      "**Modules with similar accuracy (if any) have the following hyperparameters (hyperparameters:[weight accuracy, averaged_accuracy_train ,max_accuracy_train, max_time]) : {}\n",
      "\n",
      "\n",
      "\n",
      "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
      "Weighted accuracy is 0.607 when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_folds are (3, [3, 4, 2], 1, 15000, 1e-06, 2, 200) respectively.\n",
      "\n",
      "Accuracy on test data is: 0.602, averaged accuracy on train data is: 0.613 after 15000 epoc\n",
      "This took 14767 seconds to solve.\n",
      "\n",
      "\n",
      "**The best overall accuracy on test data is so far standing at: 0.927 when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_fold are (3, [3, 4, 2], 0.001, 10000, 1e-06, 3, 200)\n",
      "**Modules with similar accuracy (if any) have the following hyperparameters (hyperparameters:[weight accuracy, averaged_accuracy_train ,max_accuracy_train, max_time]) : {}\n",
      "\n",
      "\n",
      "\n",
      "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
      "Weighted accuracy is 0.394 when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_folds are (3, [3, 4, 2], 1, 15000, 1e-06, 3, 200) respectively.\n",
      "\n",
      "Accuracy on test data is: 0.398, averaged accuracy on train data is: 0.38699999999999996 after 6 epoc\n",
      "This took 14767 seconds to solve.\n",
      "\n",
      "\n",
      "**The best overall accuracy on test data is so far standing at: 0.927 when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_fold are (3, [3, 4, 2], 0.001, 10000, 1e-06, 3, 200)\n",
      "**Modules with similar accuracy (if any) have the following hyperparameters (hyperparameters:[weight accuracy, averaged_accuracy_train ,max_accuracy_train, max_time]) : {}\n",
      "\n",
      "\n",
      "\n",
      "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
      "Weighted accuracy is 0.609 when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_folds are (3, [3, 4, 2], 1, 15000, 1e-07, 1, 200) respectively.\n",
      "\n",
      "Accuracy on test data is: 0.602, averaged accuracy on train data is: 0.613 after 21 epoc\n",
      "This took 14769 seconds to solve.\n",
      "\n",
      "\n",
      "**The best overall accuracy on test data is so far standing at: 0.927 when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_fold are (3, [3, 4, 2], 0.001, 10000, 1e-06, 3, 200)\n",
      "**Modules with similar accuracy (if any) have the following hyperparameters (hyperparameters:[weight accuracy, averaged_accuracy_train ,max_accuracy_train, max_time]) : {}\n",
      "\n",
      "\n",
      "\n",
      "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
      "Weighted accuracy is 0.607 when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_folds are (3, [3, 4, 2], 1, 15000, 1e-07, 2, 200) respectively.\n",
      "\n",
      "Accuracy on test data is: 0.602, averaged accuracy on train data is: 0.613 after 15000 epoc\n",
      "This took 15757 seconds to solve.\n",
      "\n",
      "\n",
      "**The best overall accuracy on test data is so far standing at: 0.927 when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_fold are (3, [3, 4, 2], 0.001, 10000, 1e-06, 3, 200)\n",
      "**Modules with similar accuracy (if any) have the following hyperparameters (hyperparameters:[weight accuracy, averaged_accuracy_train ,max_accuracy_train, max_time]) : {}\n",
      "\n",
      "\n",
      "\n",
      "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
      "Weighted accuracy is 0.394 when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_folds are (3, [3, 4, 2], 1, 15000, 1e-07, 3, 200) respectively.\n",
      "\n",
      "Accuracy on test data is: 0.398, averaged accuracy on train data is: 0.38699999999999996 after 6 epoc\n",
      "This took 15758 seconds to solve.\n",
      "\n",
      "\n",
      "**The best overall accuracy on test data is so far standing at: 0.927 when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_fold are (3, [3, 4, 2], 0.001, 10000, 1e-06, 3, 200)\n",
      "**Modules with similar accuracy (if any) have the following hyperparameters (hyperparameters:[weight accuracy, averaged_accuracy_train ,max_accuracy_train, max_time]) : {}\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
      "Weighted accuracy is 0.609 when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_folds are (3, [3, 4, 2], 2, 10000, 1e-06, 1, 200) respectively.\n",
      "\n",
      "Accuracy on test data is: 0.602, averaged accuracy on train data is: 0.613 after 10000 epoc\n",
      "This took 16408 seconds to solve.\n",
      "\n",
      "\n",
      "**The best overall accuracy on test data is so far standing at: 0.927 when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_fold are (3, [3, 4, 2], 0.001, 10000, 1e-06, 3, 200)\n",
      "**Modules with similar accuracy (if any) have the following hyperparameters (hyperparameters:[weight accuracy, averaged_accuracy_train ,max_accuracy_train, max_time]) : {}\n",
      "\n",
      "\n",
      "\n",
      "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
      "Weighted accuracy is 0.392 when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_folds are (3, [3, 4, 2], 2, 10000, 1e-06, 2, 200) respectively.\n",
      "\n",
      "Accuracy on test data is: 0.398, averaged accuracy on train data is: 0.38699999999999996 after 4 epoc\n",
      "This took 16408 seconds to solve.\n",
      "\n",
      "\n",
      "**The best overall accuracy on test data is so far standing at: 0.927 when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_fold are (3, [3, 4, 2], 0.001, 10000, 1e-06, 3, 200)\n",
      "**Modules with similar accuracy (if any) have the following hyperparameters (hyperparameters:[weight accuracy, averaged_accuracy_train ,max_accuracy_train, max_time]) : {}\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-fdf23be20dc9>:23: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
      "Weighted accuracy is 0.394 when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_folds are (3, [3, 4, 2], 2, 10000, 1e-06, 3, 200) respectively.\n",
      "\n",
      "Accuracy on test data is: 0.398, averaged accuracy on train data is: 0.38699999999999996 after 4 epoc\n",
      "This took 16409 seconds to solve.\n",
      "\n",
      "\n",
      "**The best overall accuracy on test data is so far standing at: 0.927 when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_fold are (3, [3, 4, 2], 0.001, 10000, 1e-06, 3, 200)\n",
      "**Modules with similar accuracy (if any) have the following hyperparameters (hyperparameters:[weight accuracy, averaged_accuracy_train ,max_accuracy_train, max_time]) : {}\n",
      "\n",
      "\n",
      "\n",
      "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
      "Weighted accuracy is 0.609 when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_folds are (3, [3, 4, 2], 2, 10000, 1e-07, 1, 200) respectively.\n",
      "\n",
      "Accuracy on test data is: 0.602, averaged accuracy on train data is: 0.613 after 10000 epoc\n",
      "This took 17072 seconds to solve.\n",
      "\n",
      "\n",
      "**The best overall accuracy on test data is so far standing at: 0.927 when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_fold are (3, [3, 4, 2], 0.001, 10000, 1e-06, 3, 200)\n",
      "**Modules with similar accuracy (if any) have the following hyperparameters (hyperparameters:[weight accuracy, averaged_accuracy_train ,max_accuracy_train, max_time]) : {}\n",
      "\n",
      "\n",
      "\n",
      "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
      "Weighted accuracy is 0.392 when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_folds are (3, [3, 4, 2], 2, 10000, 1e-07, 2, 200) respectively.\n",
      "\n",
      "Accuracy on test data is: 0.398, averaged accuracy on train data is: 0.38699999999999996 after 4 epoc\n",
      "This took 17073 seconds to solve.\n",
      "\n",
      "\n",
      "**The best overall accuracy on test data is so far standing at: 0.927 when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_fold are (3, [3, 4, 2], 0.001, 10000, 1e-06, 3, 200)\n",
      "**Modules with similar accuracy (if any) have the following hyperparameters (hyperparameters:[weight accuracy, averaged_accuracy_train ,max_accuracy_train, max_time]) : {}\n",
      "\n",
      "\n",
      "\n",
      "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
      "Weighted accuracy is 0.394 when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_folds are (3, [3, 4, 2], 2, 10000, 1e-07, 3, 200) respectively.\n",
      "\n",
      "Accuracy on test data is: 0.398, averaged accuracy on train data is: 0.38699999999999996 after 4 epoc\n",
      "This took 17073 seconds to solve.\n",
      "\n",
      "\n",
      "**The best overall accuracy on test data is so far standing at: 0.927 when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_fold are (3, [3, 4, 2], 0.001, 10000, 1e-06, 3, 200)\n",
      "**Modules with similar accuracy (if any) have the following hyperparameters (hyperparameters:[weight accuracy, averaged_accuracy_train ,max_accuracy_train, max_time]) : {}\n",
      "\n",
      "\n",
      "\n",
      "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
      "Weighted accuracy is 0.609 when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_folds are (3, [3, 4, 2], 2, 15000, 1e-06, 1, 200) respectively.\n",
      "\n",
      "Accuracy on test data is: 0.602, averaged accuracy on train data is: 0.613 after 15000 epoc\n",
      "This took 18109 seconds to solve.\n",
      "\n",
      "\n",
      "**The best overall accuracy on test data is so far standing at: 0.927 when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_fold are (3, [3, 4, 2], 0.001, 10000, 1e-06, 3, 200)\n",
      "**Modules with similar accuracy (if any) have the following hyperparameters (hyperparameters:[weight accuracy, averaged_accuracy_train ,max_accuracy_train, max_time]) : {}\n",
      "\n",
      "\n",
      "\n",
      "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
      "Weighted accuracy is 0.392 when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_folds are (3, [3, 4, 2], 2, 15000, 1e-06, 2, 200) respectively.\n",
      "\n",
      "Accuracy on test data is: 0.398, averaged accuracy on train data is: 0.38699999999999996 after 4 epoc\n",
      "This took 18109 seconds to solve.\n",
      "\n",
      "\n",
      "**The best overall accuracy on test data is so far standing at: 0.927 when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_fold are (3, [3, 4, 2], 0.001, 10000, 1e-06, 3, 200)\n",
      "**Modules with similar accuracy (if any) have the following hyperparameters (hyperparameters:[weight accuracy, averaged_accuracy_train ,max_accuracy_train, max_time]) : {}\n",
      "\n",
      "\n",
      "\n",
      "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
      "Weighted accuracy is 0.394 when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_folds are (3, [3, 4, 2], 2, 15000, 1e-06, 3, 200) respectively.\n",
      "\n",
      "Accuracy on test data is: 0.398, averaged accuracy on train data is: 0.38699999999999996 after 4 epoc\n",
      "This took 18109 seconds to solve.\n",
      "\n",
      "\n",
      "**The best overall accuracy on test data is so far standing at: 0.927 when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_fold are (3, [3, 4, 2], 0.001, 10000, 1e-06, 3, 200)\n",
      "**Modules with similar accuracy (if any) have the following hyperparameters (hyperparameters:[weight accuracy, averaged_accuracy_train ,max_accuracy_train, max_time]) : {}\n",
      "\n",
      "\n",
      "\n",
      "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
      "Weighted accuracy is 0.609 when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_folds are (3, [3, 4, 2], 2, 15000, 1e-07, 1, 200) respectively.\n",
      "\n",
      "Accuracy on test data is: 0.602, averaged accuracy on train data is: 0.613 after 15000 epoc\n",
      "This took 19176 seconds to solve.\n",
      "\n",
      "\n",
      "**The best overall accuracy on test data is so far standing at: 0.927 when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_fold are (3, [3, 4, 2], 0.001, 10000, 1e-06, 3, 200)\n",
      "**Modules with similar accuracy (if any) have the following hyperparameters (hyperparameters:[weight accuracy, averaged_accuracy_train ,max_accuracy_train, max_time]) : {}\n",
      "\n",
      "\n",
      "\n",
      "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
      "Weighted accuracy is 0.392 when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_folds are (3, [3, 4, 2], 2, 15000, 1e-07, 2, 200) respectively.\n",
      "\n",
      "Accuracy on test data is: 0.398, averaged accuracy on train data is: 0.38699999999999996 after 4 epoc\n",
      "This took 19177 seconds to solve.\n",
      "\n",
      "\n",
      "**The best overall accuracy on test data is so far standing at: 0.927 when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_fold are (3, [3, 4, 2], 0.001, 10000, 1e-06, 3, 200)\n",
      "**Modules with similar accuracy (if any) have the following hyperparameters (hyperparameters:[weight accuracy, averaged_accuracy_train ,max_accuracy_train, max_time]) : {}\n",
      "\n",
      "\n",
      "\n",
      "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
      "Weighted accuracy is 0.394 when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_folds are (3, [3, 4, 2], 2, 15000, 1e-07, 3, 200) respectively.\n",
      "\n",
      "Accuracy on test data is: 0.398, averaged accuracy on train data is: 0.38699999999999996 after 4 epoc\n",
      "This took 19177 seconds to solve.\n",
      "\n",
      "\n",
      "**The best overall accuracy on test data is so far standing at: 0.927 when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_fold are (3, [3, 4, 2], 0.001, 10000, 1e-06, 3, 200)\n",
      "**Modules with similar accuracy (if any) have the following hyperparameters (hyperparameters:[weight accuracy, averaged_accuracy_train ,max_accuracy_train, max_time]) : {}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "When number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_fold are (3, [3, 4, 2], 0.001, 10000, 1e-06, 3, 200) respectively, the expected overall weighted accuracy on unseen data is: 0.927\n",
      "This module is 0.93 accurate on test data\n",
      "Whereas, averaged accuracy on train data is 0.922, and topped at 0.94\n",
      "This module takes 1853 seconds to solve.\n",
      "Modules with similar accuracy (if any) have the following hyperparameters (hyperparameters:[weight accuracy, averaged_accuracy_train, max_accuracy_train, max_time]) : {}\n"
     ]
    }
   ],
   "source": [
    "# Neural network|selecting_hyperparameters\n",
    "\n",
    "import numpy as np\n",
    "import itertools\n",
    "import time\n",
    "\n",
    "start_time = time.process_time()\n",
    "\n",
    "training_spam = np.loadtxt(open(\"data/training_spam.csv\"), delimiter=\",\").astype(int)\n",
    "testing_spam = np.loadtxt(open(\"data/testing_spam.csv\"), delimiter=\",\").astype(int)\n",
    "test_data = testing_spam[:, 1:]\n",
    "test_labels = testing_spam[:, 0]\n",
    "\n",
    "class hidden_layer:\n",
    "    def __init__(self,n_inputs, n_of_neurons):\n",
    "        self.weights = np.random.rand(n_inputs, n_of_neurons)\n",
    "        self.biases = np.zeros([n_of_neurons,1])\n",
    "\n",
    "    def feed_forward(self, inputs):\n",
    "        return np.dot(self.weights.T, inputs) + self.biases\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "class neural_network:\n",
    "    def __init__(self, number_of_hidden_layers=2, number_of_neurons=[9,9], learning_rate=1.8, max_n_epoc=1000, error_margin= 10**-9, regularization_parameter = 0.8):\n",
    "        self.number_of_hidden_layers= number_of_hidden_layers\n",
    "        self.number_of_neurons = number_of_neurons\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_n_epoc = max_n_epoc\n",
    "        self.error_margin = error_margin\n",
    "        self.regularization_parameter = regularization_parameter\n",
    "        self.layer = []\n",
    "        self.intera = []\n",
    "        self.output = []\n",
    "        self.j = 0\n",
    "        self.Back_prop_residual = [0] * (self.number_of_hidden_layers + 1)\n",
    "\n",
    "    def FeedForward(self, x):\n",
    "        if self.j == 0:\n",
    "            first_hidden_layer = hidden_layer(x.shape[0], self.number_of_neurons[0])\n",
    "            intera = first_hidden_layer.feed_forward(x)\n",
    "            output_1 = first_hidden_layer.sigmoid(intera)\n",
    "            self.layer.append(first_hidden_layer)\n",
    "            self.intera.append(intera)\n",
    "            self.output.append(output_1)\n",
    "            output_x = output_1\n",
    "            for i in range(1, self.number_of_hidden_layers):\n",
    "                hidden_layer_x = hidden_layer(self.number_of_neurons[i - 1], self.number_of_neurons[i])\n",
    "                intera = hidden_layer_x.feed_forward(output_x)\n",
    "                output_x = hidden_layer_x.sigmoid(intera)\n",
    "                self.layer.append(hidden_layer_x)\n",
    "                self.intera.append(intera)\n",
    "                self.output.append(output_x)\n",
    "            output_layer = hidden_layer(self.number_of_neurons[-1], 1)\n",
    "            intera = output_layer.feed_forward(output_x)\n",
    "            output_final = output_layer.sigmoid(intera)\n",
    "            self.layer.append(output_layer)\n",
    "            self.intera.append(intera)\n",
    "            self.output.append(output_final)\n",
    "        else:\n",
    "            intera = self.layer[0].feed_forward(x)\n",
    "            self.intera[0] = intera\n",
    "            output_1 = self.layer[0].sigmoid(intera)\n",
    "            self.output[0] = output_1\n",
    "            output_x = output_1\n",
    "            for i in range(1, self.number_of_hidden_layers):\n",
    "                intera = self.layer[i].feed_forward(output_x)\n",
    "                self.intera[i] = intera\n",
    "                output_x = self.layer[i].sigmoid(intera)\n",
    "                self.output[i] = output_x\n",
    "            intera = self.layer[-1].feed_forward(output_x)\n",
    "            self.intera[-1] = intera\n",
    "            output_final = self.layer[-1].sigmoid(intera)\n",
    "            self.output[-1] = output_final\n",
    "        return self.output[-1]\n",
    "\n",
    "    def BackProp(self, X, y_true):\n",
    "        Back_prop = [0] * len(self.layer)\n",
    "        Back_prop[-1] = self.output[-1] - y_true\n",
    "        for i in range(1, len(self.layer)):\n",
    "            Back_prop[-i-1] = np.multiply(np.dot(self.layer[-i].weights, Back_prop[-i]) , self.derv_Sigmoid(self.output[-i-1]))\n",
    "            \n",
    "        for i in range(len(self.layer)):\n",
    "            if i==0 :\n",
    "                self.Back_prop_residual[i] = self.Back_prop_residual[i] + np.dot(Back_prop[0], X)\n",
    "\n",
    "            else:\n",
    "                self.Back_prop_residual[i] = self.Back_prop_residual[i] + np.dot(Back_prop[i],self.output[i-1].T)\n",
    "\n",
    "            \n",
    "        for i in range(len(self.layer)):\n",
    "            \n",
    "            self.layer[i].weights -= self.learning_rate * (\n",
    "                    self.Back_prop_residual[i].T / X.shape[\n",
    "                0] + self.regularization_parameter * self.layer[i].weights)\n",
    "            \n",
    "            self.layer[i].biases -= self.learning_rate * (\n",
    "                        np.sum(Back_prop[i], axis=1).reshape(self.layer[i].biases.shape) / X.shape[0])\n",
    "\n",
    "    def train(self, X, y):\n",
    "        n_epoc= 0\n",
    "        temp_cost = 0\n",
    "\n",
    "        while n_epoc <  self.max_n_epoc:\n",
    "            y_predicted_temp = self.FeedForward(X.T).T\n",
    "            current_cost = self.CostFunction(y, y_predicted_temp)\n",
    "            self.j += 1\n",
    "            delta = current_cost - temp_cost\n",
    "            if abs(delta) > self.error_margin:\n",
    "                temp_cost = current_cost\n",
    "                self.BackProp(X, y)\n",
    "            else:\n",
    "                return n_epoc\n",
    "            n_epoc += 1\n",
    "        return n_epoc\n",
    "\n",
    "\n",
    "    def CostFunction(self, y, y_predicted):\n",
    "        weights_summed = 0\n",
    "        for i in range(len(self.layer)):\n",
    "            weights_summed += np.sum(np.sum(self.layer[i].weights**2, axis=0))\n",
    "        return -(1/y.shape[0])* np.sum((y * np.log(y_predicted) + (1-y) * np.log(1-y_predicted))) + (self.regularization_parameter/ (2*y.shape[0]) * weights_summed)\n",
    "\n",
    "    def derv_Sigmoid(self, x):\n",
    "        return np.multiply(x , (1 - x))\n",
    "\n",
    "    def predict(self, new_data):\n",
    "        output_final = self.FeedForward(new_data)\n",
    "        return np.where(output_final<=0.5,0,1)\n",
    "\n",
    "\n",
    "def cross_validation(training_spam, item):\n",
    "    number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter, k_fold = item\n",
    "    x_training = training_spam[:, 1:]\n",
    "    y_training = training_spam[:, 0]\n",
    "    x = np.split(x_training, x_training.shape[0] / k_fold, axis=0)\n",
    "    y = np.split(y_training, y_training.shape[0] / k_fold, axis=0)\n",
    "    max_accuracy = 0\n",
    "    averaged_accuracy = 0\n",
    "    for i in range(len(x)):\n",
    "        x_temp = np.concatenate(x[0:i] + x[i + 1:])\n",
    "        y_temp = np.concatenate(y[0:i] + y[i + 1:])\n",
    "        classifier = neural_network(number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter)\n",
    "        n_epoc = classifier.train(x_temp, y_temp)\n",
    "\n",
    "        final_y_predict_temp = classifier.predict(x[i].T).T\n",
    "        accuracy = np.count_nonzero(final_y_predict_temp == y[i].reshape(final_y_predict_temp.shape)) / \\\n",
    "                   final_y_predict_temp.shape[0]\n",
    "\n",
    "        if accuracy > max_accuracy:\n",
    "            max_accuracy = accuracy\n",
    "            max_classifier = classifier\n",
    "        averaged_accuracy += accuracy\n",
    "    averaged_accuracy = averaged_accuracy / len(x)\n",
    "    return max_classifier, max_accuracy, averaged_accuracy, n_epoc\n",
    "\n",
    "\n",
    "def create_classifier(training_spam, item):\n",
    "    classifier = cross_validation(training_spam, item)\n",
    "    return classifier\n",
    "\n",
    "\n",
    "number_of_hidden_layers = [3]\n",
    "number_of_neurons=[[3,4,2]]\n",
    "learning_rate = [0.001,0.01, 0.1, 1, 2]\n",
    "max_n_epoc = [10000, 15000]\n",
    "error_margin= [10**-6, 10**-7]\n",
    "regularization_parameter = [1,2,3]\n",
    "k_fold =[200]\n",
    "\n",
    "\n",
    "\n",
    "output_list = list(itertools.product(number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_parameter, k_fold))\n",
    "\n",
    "\n",
    "dic = 0\n",
    "max_weighted_accuracy=0\n",
    "for item in output_list:\n",
    "    classifier,max_accuracy_train, averaged_accuracy_train, n_epoc = create_classifier(training_spam, item)\n",
    "    end_time = time.process_time()\n",
    "\n",
    "    predictions = classifier.predict(test_data.T).T\n",
    "    accuracy = np.count_nonzero(predictions == test_labels.reshape(test_labels.shape[0],1)) / test_labels.shape[0]\n",
    "    weighted_accuracy = round(accuracy * test_data.shape[0] / (test_data.shape[0] + (training_spam.shape[0] / item[-2])) \\\n",
    "                              + averaged_accuracy_train * (training_spam.shape[0] / item[-2]) / (\n",
    "                                          test_data.shape[0] + (training_spam.shape[0] / item[-2])), 3)\n",
    "\n",
    "    if weighted_accuracy > max_weighted_accuracy:\n",
    "        dic = {}\n",
    "\n",
    "        max_weighted_accuracy = weighted_accuracy\n",
    "        max_accuracy = accuracy\n",
    "        max_averaged_accuracy_train = averaged_accuracy_train\n",
    "        maxi_accuracy_train = max_accuracy_train\n",
    "\n",
    "        max_item = item\n",
    "\n",
    "        max_time = int(end_time - start_time)\n",
    "    elif weighted_accuracy == max_weighted_accuracy:\n",
    "        if accuracy > max_accuracy:\n",
    "            max_weighted_accuracy = weighted_accuracy\n",
    "            max_accuracy = accuracy\n",
    "            maxi_accuracy_train = max_accuracy_train\n",
    "            max_averaged_accuracy_train = averaged_accuracy_train\n",
    "            max_item = item\n",
    "            max_time = int(end_time - start_time)\n",
    "\n",
    "\n",
    "    print(\"&&\" * 50)\n",
    "    print(\n",
    "        f\"Weighted accuracy is {weighted_accuracy} when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_folds are {item} respectively.\")\n",
    "    print()\n",
    "    print(f\"Accuracy on test data is: {accuracy}, averaged accuracy on train data is: {averaged_accuracy_train} after {n_epoc} epoc\")\n",
    "    print(f\"This took\", int(end_time - start_time), \"seconds to solve.\")\n",
    "    print()\n",
    "    print()\n",
    "    print(\n",
    "        f\"**The best overall accuracy on test data is so far standing at: {max_weighted_accuracy} when number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_fold are {max_item}\")\n",
    "        print()\n",
    "    print()\n",
    "    print()\n",
    "\n",
    "print()\n",
    "print('^' * 250)\n",
    "print(\n",
    "    f\"When number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter and k_fold are {max_item} respectively, the expected overall weighted accuracy on unseen data is: {max_weighted_accuracy}\")\n",
    "print(f\"This module is {max_accuracy} accurate on test data\")\n",
    "print(f\"Whereas, averaged accuracy on train data is {max_averaged_accuracy_train}, and topped at {maxi_accuracy_train}\")\n",
    "print(f\"This module takes {max_time} seconds to solve.\")\n",
    "\n",
    "# pass on the result to the final module below\n",
    "number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_parameter, k_fold = max_item\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0ede49",
   "metadata": {},
   "source": [
    "#  Final Module \n",
    "\n",
    "When plugging the hyper parameters associated with the best average weighted accuracy I got when running the above code, I got a **0.93** accuracy when run on test data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "911c8fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class hidden_layer:\n",
    "    def __init__(self,n_inputs, n_of_neurons):\n",
    "        self.weights = np.random.rand(n_inputs, n_of_neurons)\n",
    "        self.biases = np.zeros([n_of_neurons,1])\n",
    "\n",
    "    def feed_forward(self, inputs):\n",
    "        return np.dot(self.weights.T, inputs) + self.biases\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "class neural_network:\n",
    "    def __init__(self, number_of_hidden_layers=3, number_of_neurons=[3,4,2], learning_rate=0.001, max_n_epoc=10000, error_margin= 10**-6, regularization_parameter = 3):\n",
    "        self.number_of_hidden_layers= number_of_hidden_layers\n",
    "        self.number_of_neurons = number_of_neurons\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_n_epoc = max_n_epoc\n",
    "        self.error_margin = error_margin\n",
    "        self.regularization_parameter = regularization_parameter\n",
    "        self.layer = []\n",
    "        self.intera = []\n",
    "        self.output = []\n",
    "        self.j = 0\n",
    "        self.Back_prop_residual = [0] * (self.number_of_hidden_layers + 1)\n",
    "\n",
    "    def FeedForward(self, x):\n",
    "        if self.j == 0:\n",
    "            first_hidden_layer = hidden_layer(x.shape[0], self.number_of_neurons[0])\n",
    "            intera = first_hidden_layer.feed_forward(x)\n",
    "            output_1 = first_hidden_layer.sigmoid(intera)\n",
    "            self.layer.append(first_hidden_layer)\n",
    "            self.intera.append(intera)\n",
    "            self.output.append(output_1)\n",
    "            output_x = output_1\n",
    "            for i in range(1, self.number_of_hidden_layers):\n",
    "                hidden_layer_x = hidden_layer(self.number_of_neurons[i - 1], self.number_of_neurons[i])\n",
    "                intera = hidden_layer_x.feed_forward(output_x)\n",
    "                output_x = hidden_layer_x.sigmoid(intera)\n",
    "                self.layer.append(hidden_layer_x)\n",
    "                self.intera.append(intera)\n",
    "                self.output.append(output_x)\n",
    "            output_layer = hidden_layer(self.number_of_neurons[-1], 1)\n",
    "            intera = output_layer.feed_forward(output_x)\n",
    "            output_final = output_layer.sigmoid(intera)\n",
    "            self.layer.append(output_layer)\n",
    "            self.intera.append(intera)\n",
    "            self.output.append(output_final)\n",
    "        else:\n",
    "            intera = self.layer[0].feed_forward(x)\n",
    "            self.intera[0] = intera\n",
    "            output_1 = self.layer[0].sigmoid(intera)\n",
    "            self.output[0] = output_1\n",
    "            output_x = output_1\n",
    "            for i in range(1, self.number_of_hidden_layers):\n",
    "                intera = self.layer[i].feed_forward(output_x)\n",
    "                self.intera[i] = intera\n",
    "                output_x = self.layer[i].sigmoid(intera)\n",
    "                self.output[i] = output_x\n",
    "            intera = self.layer[-1].feed_forward(output_x)\n",
    "            self.intera[-1] = intera\n",
    "            output_final = self.layer[-1].sigmoid(intera)\n",
    "            self.output[-1] = output_final\n",
    "        return self.output[-1]\n",
    "\n",
    "    def BackProp(self, X, y_true):\n",
    "        Back_prop = [0] * len(self.layer)\n",
    "        Back_prop[-1] = self.output[-1] - y_true\n",
    "        for i in range(1, len(self.layer)):\n",
    "            Back_prop[-i-1] = np.multiply(np.dot(self.layer[-i].weights, Back_prop[-i]) , self.derv_Sigmoid(self.output[-i-1]))\n",
    "            \n",
    "        for i in range(len(self.layer)):\n",
    "            if i==0 :\n",
    "                self.Back_prop_residual[i] = self.Back_prop_residual[i] + np.dot(Back_prop[0], X)\n",
    "\n",
    "            else:\n",
    "                self.Back_prop_residual[i] = self.Back_prop_residual[i] + np.dot(Back_prop[i],self.output[i-1].T)\n",
    "\n",
    "            \n",
    "        for i in range(len(self.layer)):\n",
    "            \n",
    "            self.layer[i].weights -= self.learning_rate * (\n",
    "                    self.Back_prop_residual[i].T / X.shape[\n",
    "                0] + self.regularization_parameter * self.layer[i].weights)\n",
    "            \n",
    "            self.layer[i].biases -= self.learning_rate * (\n",
    "                        np.sum(Back_prop[i], axis=1).reshape(self.layer[i].biases.shape) / X.shape[0])\n",
    "\n",
    "    def train(self, X, y):\n",
    "        n_epoc= 0\n",
    "        temp_cost = 0\n",
    "        while n_epoc <  self.max_n_epoc:\n",
    "            y_predicted_temp = self.FeedForward(X.T).T\n",
    "            current_cost = self.CostFunction(y, y_predicted_temp)\n",
    "            self.j += 1\n",
    "            delta = current_cost - temp_cost\n",
    "            if abs(delta) > self.error_margin:\n",
    "                temp_cost = current_cost\n",
    "                self.BackProp(X, y)\n",
    "            else:\n",
    "                return n_epoc\n",
    "            n_epoc += 1\n",
    "        return n_epoc\n",
    "\n",
    "\n",
    "    def CostFunction(self, y, y_predicted):\n",
    "        weights_summed = 0\n",
    "        for i in range(len(self.layer)):\n",
    "            weights_summed += np.sum(np.sum(self.layer[i].weights**2, axis=0))\n",
    "        return -(1/y.shape[0])* np.sum((y * np.log(y_predicted) + (1-y) * np.log(1-y_predicted))) + (self.regularization_parameter/ (2*y.shape[0]) * weights_summed)\n",
    "\n",
    "    def derv_Sigmoid(self, x):\n",
    "        return np.multiply(x , (1 - x))\n",
    "\n",
    "    def predict(self, new_data):\n",
    "        new_data=new_data.T\n",
    "        output_final = self.FeedForward(new_data)\n",
    "        return np.where(output_final<=0.5,0,1).T\n",
    "    \n",
    "\n",
    "def cross_validation(training_spam):\n",
    "    number_of_hidden_layers, number_of_neurons, learning_rate, max_n_epoc, error_margin, regularization_paramter, k_fold = item\n",
    "    x_training = training_spam[:, 1:]\n",
    "    y_training = training_spam[:, 0]\n",
    "    x = np.split(x_training, x_training.shape[0] / k_fold, axis=0)\n",
    "    y = np.split(y_training, y_training.shape[0] / k_fold, axis=0)\n",
    "    max_accuracy = 0\n",
    "    averaged_accuracy = 0\n",
    "    for i in range(len(x)):\n",
    "        x_temp = np.concatenate(x[0:i] + x[i + 1:])\n",
    "        y_temp = np.concatenate(y[0:i] + y[i + 1:])\n",
    "        classifier = neural_network()\n",
    "        n_epoc = classifier.train(x_temp, y_temp)\n",
    "\n",
    "        final_y_predict_temp = classifier.predict(x[i])\n",
    "        accuracy = np.count_nonzero(final_y_predict_temp == y[i].reshape(final_y_predict_temp.shape)) / \\\n",
    "                   final_y_predict_temp.shape[0]\n",
    "\n",
    "        if accuracy > max_accuracy:\n",
    "            max_accuracy = accuracy\n",
    "            max_classifier = classifier\n",
    "        averaged_accuracy += accuracy\n",
    "    averaged_accuracy = averaged_accuracy / len(x)\n",
    "    return max_classifier\n",
    "\n",
    "\n",
    "def create_classifier(training_spam):\n",
    "    classifier = cross_validation(training_spam)\n",
    "    return classifier\n",
    "\n",
    "classifier = create_classifier(training_spam)\n",
    "\n",
    "\n",
    "\n",
    "# import pickle\n",
    "# a_file = open(\"data2.pkl\", \"wb\")\n",
    "# pickle.dump(classifier, a_file)\n",
    "# a_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "416fef1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.neural_network object at 0x7fe3ad2bb8e0>\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "training_spam = np.loadtxt(open(\"data/training_spam.csv\"), delimiter=\",\").astype(int)\n",
    "testing_spam = np.loadtxt(open(\"data/testing_spam.csv\"), delimiter=\",\").astype(int)\n",
    "test_data = testing_spam[:, 1:]\n",
    "test_labels = testing_spam[:, 0]\n",
    "a_file = open(\"data2.pkl\", \"rb\")\n",
    "output = pickle.load(a_file)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9b2e1b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test data is: 0.928\n"
     ]
    }
   ],
   "source": [
    "# run on test data\n",
    "testing_spam = np.loadtxt(open(\"data/testing_spam.csv\"), delimiter=\",\").astype(int)\n",
    "test_data = testing_spam[:, 1:]\n",
    "test_labels = testing_spam[:, 0]\n",
    "test_labels = test_labels.reshape(test_labels.shape[0],1)\n",
    "\n",
    "predictions = classifier.predict(test_data)\n",
    "accuracy = np.count_nonzero(predictions == test_labels)/test_labels.shape[0]\n",
    "print(f\"Accuracy on test data is: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "51ec5924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     ___Confusion Matrix and Statistics___                      \n",
      "                   *****************************************                    \n",
      "\n",
      "           Reference   \n",
      "Prediction   0    1\n",
      "  0        283    18\n",
      "  1        18    181\n",
      "\n",
      "\n",
      "\n",
      "         Precision   Recall  f1-score   Support  \n",
      "      0  0.94        0.94    0.94       301\n",
      "      1  0.91        0.91    0.91        199\n",
      "\n",
      "accuracy                     0.928      500\n"
     ]
    }
   ],
   "source": [
    "def confusion_matrix(test_labels, predictions):\n",
    "    tp = tn = fp = fn = 0\n",
    "    for actual_value, predicted_value in zip(test_labels, predictions):\n",
    "        if predicted_value == actual_value:\n",
    "            if predicted_value == 1: \n",
    "                tp += 1\n",
    "            else: \n",
    "                tn += 1\n",
    "        else: \n",
    "            if predicted_value == 1:\n",
    "                fp += 1\n",
    "            else: \n",
    "                fn += 1\n",
    "    confusion_matrix = np.array([[tn, fp], [fn, tp]])\n",
    "    print('___Confusion Matrix and Statistics___'.center(80))\n",
    "    print('*****************************************'.center(80))\n",
    "    print()\n",
    "    print('           Reference   ')\n",
    "    print ('Prediction   0    1')\n",
    "    print('  0       ', confusion_matrix[0, 0],'  ',  confusion_matrix[0, 1])\n",
    "    print('  1       ', confusion_matrix[1, 0], '  ', confusion_matrix[1, 1])\n",
    "    \n",
    "    \n",
    "    accuracy = (tn+tp) / test_labels.shape[0]\n",
    "    print()\n",
    "    precision_positive =  tp / (tp+fp)\n",
    "    precision_negative = tn / (tn+fn)\n",
    "    recall_positive =  tp/ (tp+fn)\n",
    "    recall_negative = tn/ (tn+fp)\n",
    "    \n",
    "    f1_positive = 2*(precision_positive * recall_positive)/(precision_positive+recall_positive)\n",
    "    f1_negative = 2*(precision_negative * recall_negative)/(precision_negative+recall_negative)\n",
    "    print()\n",
    "    print()\n",
    "    print('         Precision   Recall  f1-score   Support  ')\n",
    "    print ('      0 ', np.round(precision_negative,2),'      ', np.round(recall_negative,2),'  ', np.round(f1_negative,2), '     ', tn+fp )\n",
    "    print ('      1 ', np.round(precision_positive,2),'      ', np.round(recall_positive,2), '  ', np.round(f1_positive,2),'      ', tp+fn )\n",
    "    print()\n",
    "    print('accuracy                    ', accuracy,'    ',test_labels.shape[0] )\n",
    "\n",
    "confusion_matrix(test_labels, predictions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d50992a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
